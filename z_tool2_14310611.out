‚úèÔ∏è Setting installed package as editable
Result file tool/result/meta-llama-Llama-3.1-70B-Instruct/pre_translate/["BFCL_v4_multiple","zh","fulltrans","nonoise"].jsonl does not exist, will be created.
For dataset file ["BFCL_v4_multiple","zh","fulltrans","nonoise"].jsonl, total entries: 200, existing entries: 0, missing entries: 200
Result file tool/result/meta-llama-Llama-3.1-70B-Instruct/pre_translate/["BFCL_v4_multiple","zh","fulltrans","para"].jsonl does not exist, will be created.
For dataset file ["BFCL_v4_multiple","zh","fulltrans","para"].jsonl, total entries: 200, existing entries: 0, missing entries: 200
Result file tool/result/meta-llama-Llama-3.1-70B-Instruct/pre_translate/["BFCL_v4_multiple","zh","fulltrans","syno"].jsonl does not exist, will be created.
For dataset file ["BFCL_v4_multiple","zh","fulltrans","syno"].jsonl, total entries: 200, existing entries: 0, missing entries: 200
Wrote aggregated questions to file: tool/result/meta-llama-Llama-3.1-70B-Instruct/pre_translate_aggregated_questions_input.jsonl
Acquiring build lock...
Building Rust extension with maturin develop...
Installed Rust extension successfully.
Released build lock.
Loading config from: tool_config_slurm2.py
Processing configuration:  <builtins.ToolConfig object at 0x7f54e3abc430>
----------PASS 1: PRE-TRANSLATE QUESTIONS----------
Creating vLLM backend for model LocalModel.Llama3_1_70B...
Creating vLLM backend for model meta-llama/Llama-3.1-70B-Instruct with 8 GPUs...
INFO 12-23 03:05:37 [model.py:637] Resolved architecture: LlamaForCausalLM
INFO 12-23 03:05:37 [model.py:1750] Using max model len 5000
INFO 12-23 03:05:40 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:05:41 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='meta-llama/Llama-3.1-70B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-70B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=meta-llama/Llama-3.1-70B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=539571)[0;0m WARNING 12-23 03:05:41 [multiproc_executor.py:880] Reducing Torch parallelism from 4 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:05:59 [parallel_state.py:1200] world_size=8 rank=6 local_rank=6 distributed_init_method=tcp://127.0.0.1:35735 backend=nccl
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:05:59 [parallel_state.py:1200] world_size=8 rank=5 local_rank=5 distributed_init_method=tcp://127.0.0.1:35735 backend=nccl
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:05:59 [parallel_state.py:1200] world_size=8 rank=3 local_rank=3 distributed_init_method=tcp://127.0.0.1:35735 backend=nccl
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:05:59 [parallel_state.py:1200] world_size=8 rank=1 local_rank=1 distributed_init_method=tcp://127.0.0.1:35735 backend=nccl
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:05:59 [parallel_state.py:1200] world_size=8 rank=2 local_rank=2 distributed_init_method=tcp://127.0.0.1:35735 backend=nccl
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:05:59 [parallel_state.py:1200] world_size=8 rank=0 local_rank=0 distributed_init_method=tcp://127.0.0.1:35735 backend=nccl
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:05:59 [parallel_state.py:1200] world_size=8 rank=7 local_rank=7 distributed_init_method=tcp://127.0.0.1:35735 backend=nccl
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:05:59 [parallel_state.py:1200] world_size=8 rank=4 local_rank=4 distributed_init_method=tcp://127.0.0.1:35735 backend=nccl
[0;36m(EngineCore_DP0 pid=539571)[0;0m INFO 12-23 03:06:00 [pynccl.py:111] vLLM is using nccl==2.27.5
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750] WorkerProc failed to start.
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py", line 722, in worker_main
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     worker = WorkerProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py", line 553, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     self.worker.init_device()
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/worker_base.py", line 326, in init_device
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     self.worker.init_device()  # type: ignore
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 216, in init_device
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     init_worker_distributed_environment(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         self.vllm_config,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ...<3 lines>...
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         current_platform.dist_backend,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 913, in init_worker_distributed_environment
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ensure_model_parallel_initialized(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         parallel_config.tensor_parallel_size,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         parallel_config.decode_context_parallel_size,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/distributed/parallel_state.py", line 1435, in ensure_model_parallel_initialized
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     initialize_model_parallel(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ~~~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         tensor_model_parallel_size,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ...<3 lines>...
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         backend,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/distributed/parallel_state.py", line 1335, in initialize_model_parallel
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     _TP = init_model_parallel_group(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         group_ranks,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ...<3 lines>...
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         group_name="tp",
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/distributed/parallel_state.py", line 1062, in init_model_parallel_group
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     return GroupCoordinator(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         group_ranks=group_ranks,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         group_name=group_name,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/distributed/parallel_state.py", line 364, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     self.device_communicator = device_comm_cls(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]                                ~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         cpu_group=self.cpu_group,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         unique_name=self.unique_name,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/distributed/device_communicators/cuda_communicator.py", line 58, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     self.pynccl_comm = PyNcclCommunicator(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]                        ~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         group=self.cpu_group,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         device=self.device,
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/distributed/device_communicators/pynccl.py", line 139, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     self.comm: ncclComm_t = self.nccl.ncclCommInitRank(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         self.world_size, self.unique_id, self.rank
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/distributed/device_communicators/pynccl_wrapper.py", line 400, in ncclCommInitRank
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     self.NCCL_CHECK(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         self._funcs["ncclCommInitRank"](
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]             ctypes.byref(comm), world_size, unique_id, rank
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]         ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/distributed/device_communicators/pynccl_wrapper.py", line 366, in NCCL_CHECK
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750]     raise RuntimeError(f"NCCL error: {error_str}")
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:05 [multiproc_executor.py:750] RuntimeError: NCCL error: unhandled cuda error (run with NCCL_DEBUG=INFO for details)
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     super().__init__(vllm_config)
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py", line 174, in _init_executor
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     self.workers = WorkerProc.wait_for_ready(unready_workers)
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py", line 660, in wait_for_ready
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843]     raise e from None
[0;36m(EngineCore_DP0 pid=539571)[0;0m ERROR 12-23 03:06:09 [core.py:843] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
Creating vLLM backend for model LocalModel.Llama3_1_70B...
Creating vLLM backend for model meta-llama/Llama-3.1-70B-Instruct with 8 GPUs...
INFO 12-23 03:06:11 [model.py:637] Resolved architecture: LlamaForCausalLM
INFO 12-23 03:06:11 [model.py:1750] Using max model len 5000
INFO 12-23 03:06:11 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:12 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='meta-llama/Llama-3.1-70B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-70B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=meta-llama/Llama-3.1-70B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=540147)[0;0m WARNING 12-23 03:06:12 [multiproc_executor.py:880] Reducing Torch parallelism from 4 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:21 [parallel_state.py:1200] world_size=8 rank=3 local_rank=3 distributed_init_method=tcp://127.0.0.1:35013 backend=nccl
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:21 [parallel_state.py:1200] world_size=8 rank=6 local_rank=6 distributed_init_method=tcp://127.0.0.1:35013 backend=nccl
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:21 [parallel_state.py:1200] world_size=8 rank=0 local_rank=0 distributed_init_method=tcp://127.0.0.1:35013 backend=nccl
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:21 [parallel_state.py:1200] world_size=8 rank=1 local_rank=1 distributed_init_method=tcp://127.0.0.1:35013 backend=nccl
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:21 [parallel_state.py:1200] world_size=8 rank=7 local_rank=7 distributed_init_method=tcp://127.0.0.1:35013 backend=nccl
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:21 [parallel_state.py:1200] world_size=8 rank=5 local_rank=5 distributed_init_method=tcp://127.0.0.1:35013 backend=nccl
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:21 [parallel_state.py:1200] world_size=8 rank=4 local_rank=4 distributed_init_method=tcp://127.0.0.1:35013 backend=nccl
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:21 [parallel_state.py:1200] world_size=8 rank=2 local_rank=2 distributed_init_method=tcp://127.0.0.1:35013 backend=nccl
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:22 [pynccl.py:111] vLLM is using nccl==2.27.5
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:26 [parallel_state.py:1408] rank 2 in world size 8 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 2, EP rank 2
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:26 [parallel_state.py:1408] rank 5 in world size 8 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 5, EP rank 5
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:26 [parallel_state.py:1408] rank 6 in world size 8 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 6, EP rank 6
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:26 [parallel_state.py:1408] rank 7 in world size 8 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 7, EP rank 7
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:26 [parallel_state.py:1408] rank 3 in world size 8 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 3, EP rank 3
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:26 [parallel_state.py:1408] rank 0 in world size 8 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:26 [parallel_state.py:1408] rank 4 in world size 8 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 4, EP rank 4
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:06:26 [parallel_state.py:1408] rank 1 in world size 8 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:06:27 [gpu_model_runner.py:3467] Starting to load model meta-llama/Llama-3.1-70B-Instruct...
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP5 pid=540163)[0;0m INFO 12-23 03:06:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:06:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP2 pid=540157)[0;0m INFO 12-23 03:06:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP1 pid=540155)[0;0m INFO 12-23 03:06:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP6 pid=540165)[0;0m INFO 12-23 03:06:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP4 pid=540161)[0;0m INFO 12-23 03:06:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP3 pid=540159)[0;0m INFO 12-23 03:06:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP7 pid=540167)[0;0m INFO 12-23 03:06:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:07:47 [default_loader.py:308] Loading weights took 72.94 seconds
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:07:48 [gpu_model_runner.py:3549] Model loading took 16.4607 GiB memory and 78.579365 seconds
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:08:26 [backends.py:655] Using cache directory: /u/zluo8/.cache/vllm/torch_compile_cache/b664ddeda6/rank_0_0/backbone for vLLM's torch.compile
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:08:26 [backends.py:715] Dynamo bytecode transform time: 37.03 s
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP7 pid=540167)[0;0m INFO 12-23 03:08:38 [backends.py:216] Directly load the compiled graph(s) for dynamic shape from the cache, took 11.118 s
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP4 pid=540161)[0;0m INFO 12-23 03:08:38 [backends.py:216] Directly load the compiled graph(s) for dynamic shape from the cache, took 11.462 s
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:08:39 [backends.py:216] Directly load the compiled graph(s) for dynamic shape from the cache, took 11.422 s
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP3 pid=540159)[0;0m INFO 12-23 03:08:39 [backends.py:216] Directly load the compiled graph(s) for dynamic shape from the cache, took 11.462 s
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP2 pid=540157)[0;0m INFO 12-23 03:08:39 [backends.py:216] Directly load the compiled graph(s) for dynamic shape from the cache, took 11.834 s
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP1 pid=540155)[0;0m INFO 12-23 03:08:39 [backends.py:216] Directly load the compiled graph(s) for dynamic shape from the cache, took 11.959 s
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP5 pid=540163)[0;0m INFO 12-23 03:08:39 [backends.py:216] Directly load the compiled graph(s) for dynamic shape from the cache, took 12.006 s
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP6 pid=540165)[0;0m INFO 12-23 03:08:40 [backends.py:216] Directly load the compiled graph(s) for dynamic shape from the cache, took 12.537 s
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:08:48 [shm_broadcast.py:501] No available shared memory broadcast block found in 60 seconds. This typically happens when some processes are hanging or doing some time-consuming work (e.g. compilation, weight/kv cache quantization).
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:08:52 [monitor.py:34] torch.compile takes 48.45 s in total
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:08:57 [gpu_worker.py:359] Available KV cache memory: 108.06 GiB
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:08:59 [kv_cache_utils.py:1286] GPU KV cache size: 2,832,768 tokens
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:08:59 [kv_cache_utils.py:1291] Maximum concurrency for 5,000 tokens per request: 565.65x
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP4 pid=540161)[0;0m INFO 12-23 03:09:17 [custom_all_reduce.py:216] Registering 1288 cuda graph addresses
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP6 pid=540165)[0;0m INFO 12-23 03:09:17 [custom_all_reduce.py:216] Registering 1288 cuda graph addresses
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP2 pid=540157)[0;0m INFO 12-23 03:09:17 [custom_all_reduce.py:216] Registering 1288 cuda graph addresses
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP1 pid=540155)[0;0m INFO 12-23 03:09:17 [custom_all_reduce.py:216] Registering 1288 cuda graph addresses
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP7 pid=540167)[0;0m INFO 12-23 03:09:17 [custom_all_reduce.py:216] Registering 1288 cuda graph addresses
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP3 pid=540159)[0;0m INFO 12-23 03:09:17 [custom_all_reduce.py:216] Registering 1288 cuda graph addresses
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:09:17 [custom_all_reduce.py:216] Registering 1288 cuda graph addresses
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP5 pid=540163)[0;0m INFO 12-23 03:09:17 [custom_all_reduce.py:216] Registering 1288 cuda graph addresses
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m INFO 12-23 03:09:18 [gpu_model_runner.py:4466] Graph capturing finished in 19 secs, took 0.88 GiB
[0;36m(EngineCore_DP0 pid=540147)[0;0m INFO 12-23 03:09:19 [core.py:254] init engine (profile, create kv cache, warmup model) took 90.66 seconds
vLLM backend created successfully for meta-llama/Llama-3.1-70B-Instruct
vLLM backend created successfully for model LocalModel.Llama3_1_70B
ERROR 12-23 03:09:24 [core_client.py:600] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
