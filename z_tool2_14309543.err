ğŸ”— Found pyo3 bindings
ğŸ Found CPython 3.13 at /projects/bfdz/zluo8/tool_and_judge2/.venv/bin/python
   Compiling codebase_rs v0.1.0 (/projects/bfdz/zluo8/tool_and_judge2)
    Finished `release` profile [optimized] target(s) in 15.44s
ğŸ“– Found type stub file at codebase_rs.pyi
ğŸ“¦ Built wheel for CPython 3.13 to /tmp/.tmpL2Rr4Q/codebase_rs-0.1.0-cp313-cp313-linux_x86_64.whl
ğŸ›  Installed codebase_rs-0.1.0
/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py:1041: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/30 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:   3% Completed | 1/30 [00:03<01:42,  3.54s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:   7% Completed | 2/30 [00:08<02:03,  4.42s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  10% Completed | 3/30 [00:12<01:56,  4.31s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  13% Completed | 4/30 [00:16<01:49,  4.20s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  17% Completed | 5/30 [00:22<01:55,  4.62s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  20% Completed | 6/30 [00:26<01:46,  4.46s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  23% Completed | 7/30 [00:30<01:38,  4.28s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  27% Completed | 8/30 [00:33<01:30,  4.11s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  30% Completed | 9/30 [00:37<01:21,  3.90s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  33% Completed | 10/30 [00:41<01:17,  3.87s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  37% Completed | 11/30 [00:45<01:15,  3.95s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  40% Completed | 12/30 [00:48<01:08,  3.78s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  43% Completed | 13/30 [00:49<00:50,  2.99s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  47% Completed | 14/30 [00:53<00:51,  3.23s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  50% Completed | 15/30 [00:56<00:47,  3.18s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  53% Completed | 16/30 [00:59<00:42,  3.07s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  57% Completed | 17/30 [01:03<00:42,  3.28s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  60% Completed | 18/30 [01:06<00:39,  3.30s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  63% Completed | 19/30 [01:10<00:38,  3.47s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  67% Completed | 20/30 [01:14<00:35,  3.50s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  70% Completed | 21/30 [01:17<00:31,  3.45s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  73% Completed | 22/30 [01:21<00:28,  3.56s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  77% Completed | 23/30 [01:24<00:24,  3.54s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  80% Completed | 24/30 [01:28<00:21,  3.53s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  83% Completed | 25/30 [01:31<00:17,  3.48s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  87% Completed | 26/30 [01:34<00:12,  3.20s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  90% Completed | 27/30 [01:36<00:09,  3.08s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  93% Completed | 28/30 [01:39<00:05,  2.95s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards:  97% Completed | 29/30 [01:42<00:02,  2.85s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards: 100% Completed | 30/30 [01:44<00:00,  2.81s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Loading safetensors checkpoint shards: 100% Completed | 30/30 [01:44<00:00,  3.50s/it]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m 
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP7 pid=1942483)[0;0m 2025-12-22 20:49:14,327 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP3 pid=1942475)[0;0m 2025-12-22 20:49:14,327 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m 2025-12-22 20:49:14,327 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP6 pid=1942481)[0;0m 2025-12-22 20:49:14,327 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP4 pid=1942477)[0;0m 2025-12-22 20:49:14,327 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP5 pid=1942479)[0;0m 2025-12-22 20:49:14,327 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP2 pid=1942473)[0;0m 2025-12-22 20:49:14,327 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP1 pid=1942471)[0;0m 2025-12-22 20:49:14,327 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP4 pid=1942477)[0;0m 2025-12-22 20:49:14,384 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP1 pid=1942471)[0;0m 2025-12-22 20:49:14,384 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP2 pid=1942473)[0;0m 2025-12-22 20:49:14,389 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP7 pid=1942483)[0;0m 2025-12-22 20:49:14,454 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP3 pid=1942475)[0;0m 2025-12-22 20:49:14,463 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP5 pid=1942479)[0;0m 2025-12-22 20:49:14,465 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m 2025-12-22 20:49:14,467 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP6 pid=1942481)[0;0m 2025-12-22 20:49:14,469 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–         | 1/35 [00:00<00:25,  1.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 2/35 [00:01<00:16,  1.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–Š         | 3/35 [00:01<00:13,  2.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|â–ˆâ–        | 4/35 [00:01<00:10,  2.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|â–ˆâ–        | 5/35 [00:01<00:09,  3.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|â–ˆâ–‹        | 6/35 [00:02<00:08,  3.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|â–ˆâ–ˆ        | 7/35 [00:02<00:08,  3.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|â–ˆâ–ˆâ–       | 8/35 [00:02<00:07,  3.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:03<00:07,  3.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|â–ˆâ–ˆâ–Š       | 10/35 [00:03<00:06,  3.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 11/35 [00:03<00:06,  3.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:03<00:06,  3.69it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [00:04<00:06,  3.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14/35 [00:04<00:05,  3.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/35 [00:04<00:05,  3.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 16/35 [00:04<00:05,  3.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 17/35 [00:05<00:05,  3.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:05<00:05,  3.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/35 [00:06<00:05,  2.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 20/35 [00:06<00:05,  2.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:06<00:04,  2.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 22/35 [00:07<00:04,  2.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 23/35 [00:07<00:03,  3.02it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:07<00:03,  2.91it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 25/35 [00:08<00:03,  2.67it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/35 [00:08<00:03,  2.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:08<00:02,  3.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [00:09<00:02,  3.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 29/35 [00:09<00:02,  3.00it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:09<00:01,  2.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [00:10<00:01,  3.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [00:10<00:00,  3.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [00:10<00:00,  3.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [00:10<00:00,  3.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:10<00:00,  4.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:10<00:00,  3.20it/s]
[0;36m(EngineCore_DP0 pid=1942462)[0;0m [0;36m(Worker_TP0 pid=1942469)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   5%|â–Œ         | 1/19 [00:00<00:15,  1.13it/s]Capturing CUDA graphs (decode, FULL):  11%|â–ˆ         | 2/19 [00:01<00:08,  1.96it/s]Capturing CUDA graphs (decode, FULL):  16%|â–ˆâ–Œ        | 3/19 [00:01<00:06,  2.37it/s]Capturing CUDA graphs (decode, FULL):  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.69it/s]Capturing CUDA graphs (decode, FULL):  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:04,  2.94it/s]Capturing CUDA graphs (decode, FULL):  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:03,  3.31it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:03,  3.98it/s]Capturing CUDA graphs (decode, FULL):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:02,  3.91it/s]Capturing CUDA graphs (decode, FULL):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:02,  3.76it/s]Capturing CUDA graphs (decode, FULL):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 10/19 [00:03<00:02,  3.73it/s]Capturing CUDA graphs (decode, FULL):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  3.57it/s]Capturing CUDA graphs (decode, FULL):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 12/19 [00:03<00:01,  3.59it/s]Capturing CUDA graphs (decode, FULL):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:03<00:01,  4.33it/s]Capturing CUDA graphs (decode, FULL):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 14/19 [00:04<00:01,  4.20it/s]Capturing CUDA graphs (decode, FULL):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:04<00:01,  3.99it/s]Capturing CUDA graphs (decode, FULL):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:04<00:00,  5.59it/s]Capturing CUDA graphs (decode, FULL):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:04<00:00,  6.27it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  3.91it/s]
[2025-12-22 20:49:44] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:45] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:46] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:46] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:46] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:46] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:46] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:46] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:46] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:47] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:47] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:47] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:47] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:47] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:48] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:48] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:48] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:51] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-12-22 20:49:51] INFO _client.py:1740: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
Exception ignored in: <function AsyncLLM.__del__ at 0x7fbe1112a2a0>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/async_llm.py", line 263, in __del__
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/async_llm.py", line 268, in shutdown
TypeError: 'NoneType' object is not callable
