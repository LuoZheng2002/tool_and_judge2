üîó Found pyo3 bindings
üêç Found CPython 3.13 at /projects/bfdz/zluo8/tool_and_judge2/.venv/bin/python
    Finished `release` profile [optimized] target(s) in 1.06s
üìñ Found type stub file at codebase_rs.pyi
üì¶ Built wheel for CPython 3.13 to /tmp/.tmpr6zE6c/codebase_rs-0.1.0-cp313-cp313-linux_x86_64.whl
üõ† Installed codebase_rs-0.1.0
/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py:1041: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ~~~~~~~~~~~~~~~^
        path_or_repo_id,
        ^^^^^^^^^^^^^^^^
    ...<10 lines>...
        local_files_only=local_files_only,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
        # Destination
    ...<14 lines>...
        force_download=force_download,
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        method="HEAD",
    ...<5 lines>...
        timeout=timeout,
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
        method=method,
    ...<2 lines>...
        **params,
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-5ca6097c2246e74c3a66cc9d;2008f996-f130-41e8-845e-c75a90846b0f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 456, in <module>
    asyncio.run(main_async())
    ~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/asyncio/base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 178, in main_async
    await collect_all_question_translations_async(question_entries)
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 173, in collect_all_question_translations_async
    result = await coro
             ^^^^^^^^^^
  File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/asyncio/tasks.py", line 634, in _wait_for_one
    return f.result() if resolve else f
           ~~~~~~~~^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
        pretrained_model_name_or_path,
    ...<12 lines>...
        _commit_hash=commit_hash,
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-3' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-2d037b094dd5fa8540e24409;8c91f0af-680f-4d47-843d-871680052e7d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-4' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-7b1ac08853f01697223e0c18;af7cf3b0-e525-4580-b8ef-970d524007e2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-5' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-2281d137773233f95f505f48;01eb1873-f335-4801-8422-b81012b0e92f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-6' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-789e587842d52a450918220f;5a5174ef-25d8-4f0c-857a-fedc12734509)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-7' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-7e4eb5e6695a11707d871781;2271cf44-a4dc-4216-8096-94e16dd47dab)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-8' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-7bbb533926ce065e531a6856;1de3e68b-82a2-4116-af6a-b9fa42cfe1f6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-9' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-6aa7a5840e118cbc153df783;57bec4e7-3b4e-43d8-ab44-8a968c1f2455)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-10' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-5807de706e7fcacc4cb48929;39547946-a25e-4dfe-965a-7b0859398388)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-11' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-0b4c24e434153a9a67853681;afb7acd7-2d15-4529-b102-4fd168f8094e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-12' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-2d6aae7e61a073ac68575be9;da102b15-03b9-41f4-ab15-3866d42a9e48)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-13' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-2a8afc972dbd6b6c0b50936f;bff0f0db-5f23-412f-b723-27e3bded0635)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-14' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-3fbd19a401cfd0851bfd5bf1;38c2373b-abe9-4958-8c96-9bd813b56b9a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-15' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-28e1e40d4f191e807f86b6a7;53f13c61-ff0a-4c0c-9e68-79c3d3f48225)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-16' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-58a7dc0933cd77d27e6052dd;93bb4eb7-9b15-479d-a1a8-5350f4dae62d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-17' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-00304bac670febac1d9c109f;aaed38db-8219-4144-89bf-1848339384d8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-18' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-65f32f651821f04d5f499774;c4b0f5e3-5e3e-444b-853e-444711fb9cb7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-19' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-0e032081344b8aa24f4ea20f;59a021ee-0559-487d-9ee3-e9bea91e4344)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-20' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-72f28da65ce7659a65bba418;e5074861-4cd8-4704-bc60-ed68d9a5c3d0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-21' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-6625b52f1dae52b10572f551;2aba9a86-422e-4df6-9283-8d961d7ce750)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-22' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b62-0d963f6e1a592b0643fbf48e;24e3eeee-f2a5-4ca9-b751-fd70ae8eba01)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-23' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-5212340a1105d4973015fd81;6fd66879-3daa-4c6e-8d74-d32c1ae10832)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-24' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-2f1f3c122e8f5e2136c67dab;f778433b-f6bb-454f-9c17-cccd44c09e47)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-25' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-16d6a0d5368fd41b502eabca;b0d3667f-54ee-4b48-b435-7db768c73e8f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-26' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-344fff6710be064f3ff3c5ca;960de605-ab66-4ef4-86e2-435d803bb216)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-27' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-5907e4dd0317550e0ff6e246;8073642f-2f5d-4368-ae07-f976f705c57f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-28' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-25333ede7cd67baa10f10400;6e707e0f-a1cc-4c65-b010-8ba5202efa43)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-29' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-795f376124652ff935a4ee3a;4ea3f880-30af-49c1-90e2-d5a748fd9b0d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-30' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-6aea54b670a99a74672b00fe;94906a49-5f6a-441c-9495-6cee5c7e91a6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-31' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-37f1fd8a060e32c9426aba5e;16b85328-6a5a-4413-baab-c3398a0fce70)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-32' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-268f3a5c65fc0a6c0751118a;5f54b846-a394-4a28-8927-8ad4a055a7af)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-33' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-5f523c752aaedbe0195ff524;edf90dcb-7ff4-4284-8360-182cbbad66b7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-34' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-3759e793598354fd6302faea;f35f3254-8356-450f-a21d-20cf78ec96a9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-35' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-41504f4e0da30c325408619a;cef3d437-1570-4858-bfe6-16f217ccdb62)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-36' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-5ebfd4205f96b0af6eaf2759;1d2b0f51-8ff5-43bc-8ec2-337ca5b59570)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-37' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b63-33547a2873bbea5b0dcbe4f6;f7a2661e-e782-4497-a4a7-9693ca7d28ea)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-38' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-6131559850aba32e760dd19d;43ae03f4-6539-4264-b6bb-fc6179ceb878)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-39' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-38fad6746010fece353eed10;1d083bbd-7d84-4d73-a63a-a10721a5486d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-40' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-496400123557fc6537c86fe6;8cd760cc-31ae-4db9-a91b-43d80943edc4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-41' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-5d5c773c4f9df11227b6a24f;ab500354-bb55-4da7-86df-706f41a33c6e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-42' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-3c0768e000a94d8a06f17403;c56557d2-60f3-40d0-9ff6-fed2d72c1849)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-43' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-48d705485fd728a0547ef2e5;173cb2db-f23e-43d7-8cb4-e873d5ae4ed0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-44' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-46c455be69f8e1f2354a5eb3;23b6e811-c3b4-44c7-b045-b7d13cc4c326)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-45' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-39d7bf0d7597413b77e75af1;87def790-3365-4b13-b27c-b1d6935b63e1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-46' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-32699fec669690ae1031a81a;8b0c0aa6-0fa6-4ce9-b618-74f5fe477fe8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-47' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-75fe577f016e58cf1b1b4981;f232ed1d-8785-433e-8444-b88220d8b3e1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-48' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b64-765043bc435883284d74feef;c0b0de66-1c48-4928-be41-dd53a77a23b3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-49' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-501bb5c41932da300df0b4f4;eac4e603-4653-459f-aa0c-7c342351564f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-50' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-145d889e45db872e36720d22;05b4b40d-93b1-4e54-bbd8-b1e57d3523ef)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-51' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-3a3197b902ee43033bf09eb9;6121c093-4292-4534-810e-7f0f6e58baf6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-52' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-5713c7c949ca820220b70559;38def79e-e524-4378-85d8-45a2eb0565f1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-53' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-29c784f55cd0a9901fee6d0d;cad7a73b-5eea-49ca-bed3-a2876bbd7fc3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-54' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-3a36b327446e08d10cf96fbe;e61e929e-06e9-433b-98ad-705699dd767c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-55' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-2cc4e06e7cf23f19457f00d8;62139ec8-c021-433d-a2c3-f14b33187522)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-56' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-3ec4e24017d0934420d1264c;58474c31-b1ff-4491-8591-dd05dffe65ff)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-57' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-36f0c5697047d34d5733edde;f42c9a5d-a584-4eb5-a34a-ae2828235ad7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-58' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-0b4b590f377eba391819b092;288df3ab-d844-4b77-a869-72095214fade)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-59' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-0348262411d7c50f7ba5bc2e;9d35b282-2a8f-4086-87c0-34f5b261b106)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-60' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-652e3a50696025df3fc58c85;b837df25-209a-4e8c-ab4b-b39a9b62d2c2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-61' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-0fb3b1dd6e29a8d7346be082;ffd57142-ae09-4606-b2e3-31d41dbeefb8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-62' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-2d893f146b3e6c5b2dbbb6a5;ee1bf657-3a09-4374-b17e-7d7f8546132d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-63' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-0dc1b62056225861719eff54;1ac40aa0-f248-492a-b703-f9c63cb11549)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-64' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-50db9ad34d1e17017fcbc438;be3ff8c8-bb95-42bc-a14a-d5c32929913f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-65' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-2cdbe5a9025a8fa24b00612d;2df7ba3a-f64c-43ec-826d-0039c421b81b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-66' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b65-2952a6692e132fb64b08de2c;a9684451-09b5-4578-943a-180b57467c48)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-67' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-70629a4b202d938239ff67ac;71a872c0-72e1-484f-9dec-311eebb2f844)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-68' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-0702f0bc3f6b634f18114252;547260dd-158c-476c-8386-30bb3ea24cd0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-69' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-68bbe4a70a2eb47944e5c4d8;18575bfd-f918-41a2-860d-7c12b3bd00ad)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-70' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-115fdd16345b37596b9034f2;24aa0d3d-f3ae-4f4a-a80c-960bbf5ebff8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-71' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-04821e4a0091a66727297526;cb694f89-1b44-45ed-8683-bd814f0cb663)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-72' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-7b0ac8865aaa8bb532eb447f;ef5318c1-4813-48fd-9644-91cd225b315d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-73' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-259a8b0505b28f83012b6543;fe8d1057-75c1-4e52-a0a8-0bb414f3cc94)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-74' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-6b2736ba14b5cd5023d1685d;f3436633-c206-403a-b056-bdec0b55015c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-75' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-4f53aa367f6413610c37d732;4f16adbe-0fa4-4952-aafb-cb5242cc1e4c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-76' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-15567bea2a324533586e8699;f028523f-2c23-4fca-a886-7d8d44598e58)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-77' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-644fda083d93639216aed132;49762a0d-eed0-46b9-94be-44cab797c089)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-78' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-5565e5185161ae11327ecfed;f2fc9606-3ddc-4b18-813a-41eda8e9e25b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-79' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b66-1103c8193d0b912d1a6fe39f;7127a23a-dc24-47b6-a8ab-60c846cd1e59)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-80' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-0c652c2d6593333d099f6009;9d4e6970-aba6-4ff2-b20a-4ea150eb6ebe)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-81' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-4b3544043415acf154297362;d4922dcb-487d-43b2-91f7-56cfb63485ae)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-82' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-2e7b4ba6287d79d018d79a96;2f96cc93-ece3-488e-b513-ac1f38ef2233)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-83' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-5365b7776622b66b290adf98;d7dc32c4-a687-4764-adcf-060a4ecb6409)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-84' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-1ba3813c1dbe40093532a976;e622dedc-d941-4076-b2b8-62c317d911a1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-85' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-14e4560325f3d9dc6f0ed12c;3c6f120e-f679-4c4f-88af-d75f6647ffaa)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-86' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-2ea3641a3deb7d4e5ece4765;749ba716-1ca1-4b88-8d97-5c69545e8a6f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-87' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-7d6e2b296a2cb8ae2e10f7c8;6af1a1f0-8bf4-448a-81b6-5e8a509c6e93)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-88' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-7fc8bc9504071ac7412f6606;16eb1014-5be4-40a6-8187-0dcd0ee57386)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-89' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-398bcf952f6db94205236307;07689237-12a1-4ea2-848d-b45da8d8d388)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-90' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-7c380753078f917011de312e;5cdf844e-f10c-4274-9aca-87d60ddc8b68)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-91' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-6a4536987a7980b541b5f348;d09009bf-b499-4b7c-94ef-8a0eff8e5a21)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-92' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-186596ea3adc686d71f149e1;75fd67f0-5dc5-47ea-8006-bfc0fc4cb6a8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-93' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-736fea8503c5a03c27dfd64a;08898cec-7d2f-4ec9-ad76-ad36cd07bce4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-94' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-6fb373464a6037ac5c759403;b4c6088b-fef3-412f-ae13-1f89068ce48c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-95' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-4610e8e0215501db26087683;f421849a-1acb-4c10-9162-125dfae08b49)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-96' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-6d5beaa7661b2e7c2eb27127;b221590b-697f-45fa-9868-e35b960851a3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-97' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-020dba1038ed44057ff1e1e4;480a3c4f-3284-4ca6-8865-d650ace0bbf2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-98' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-63bb7e3f24f3009224839d21;ffde7b5e-78c9-4d2c-9eca-415315cfc2b3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-99' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-09452dfd6af602ae18808602;5f131df9-eac7-415f-8977-fdfaa014e12c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-100' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b67-0c18dec9524f818348be2397;05a75be6-4f3f-4de1-a9bf-39810a7e80a3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-101' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-4af6ec29066b3e8f5fece739;ba26b6e2-4b31-4df7-a8d9-947d789511f6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-102' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-72f2ca9f3aef8b1339d560ab;c2d38dbf-0845-402e-8af3-182d3733c4d5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-103' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-4a99d8f36ade57dc59458e5a;6d3f4cc2-bf1a-4048-bec9-5e04249ff00f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-104' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-4f0026a2531def9a5a9490a2;848b901b-3164-41f7-8509-7f2ff75f98ac)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-105' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-40568cba50ddb6824632b1c3;a01243fd-bfb5-43e0-93d3-b88dfe1f16f8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-106' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-70cae437408bfd3b25d4a1ab;38456ac6-8171-490b-ab65-3456ef0329e1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-107' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-1214edc1170e71fe292a6452;008c94ab-74c7-4830-8804-bdf7ff7df8b3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-108' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-07490b5a43344ec7507811ac;ecc8ec6b-5450-4220-b399-319b5e085d8a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-109' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-312deb850e8463e4519f7a43;04465cdc-aecf-4d05-a2a6-7d2da7305f8a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-110' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-6f2960f938775a51078a2e9c;914ffb2e-f573-4301-8aa3-38ec0caa72f7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-111' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-397e205b40d26dd4173b1fbd;496dd39a-2f56-46e4-96de-24500112945f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-112' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-4519cd60551b4bc63710e152;61cde404-41a5-470a-807b-a775d08fc8ca)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-113' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-60193ac52a5203a7481d9a42;dad6cd2b-59d0-4bd6-acb5-18bec68bec35)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-114' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-2b73dbb40bf511992b973420;40e34406-aed9-45fd-b93a-c23e8230d743)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-115' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-5de310335b3245df11f1df7d;e34d7cb0-ecc4-4548-b9a2-5bccccb954e9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-116' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-2fbdd0165d7209cc516841b0;e4b24e97-8ee5-4523-abc3-53943e57b146)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-117' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-5c11a1425b059f0c02b33d7d;e4b5786d-a799-43e4-be15-7fc0793110a2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-118' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-4bff42f93e22a1164fe62ce8;8164f6b9-1424-4b5c-84a6-3e34b85935ab)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-119' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-25a5a22f4b72f4a70aadb1a2;897d1d86-f398-45a7-99bb-369106573503)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-120' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-4728796440fda6c37f2c2740;292d1715-4914-4eef-8259-cfec7b0a8a5d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-121' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b68-1da80bfe27b578073f5a8ef2;2949bae4-e7eb-4b12-acf4-4bb9b9969c97)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-122' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-1d5e350d75821ccf260d6032;def913f6-d87f-4ec8-8435-d6358aef3392)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-123' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-3940ae09040ac2e33bc7e8c5;9f1795e2-9f52-46df-96ac-5076eb435d27)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-124' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-280986c10e5c28681cbea581;13c6ea32-9b64-45e7-a41a-ea1818f85b47)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-125' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-3edf801661cef2665805988b;f513fb22-987b-459b-bd08-dd2bedc35097)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-126' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-18b0c8784a34d6bd34d8d477;d49c0126-3b49-44ab-8bf4-6b780fced18e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-127' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-0dd09b9b339f0d5c11e66918;5bd3657f-c3cb-46de-a80b-6280048db9cf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-128' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-5fe342853979d3943f40cc3b;f786470f-689b-4c51-82ae-eb09baf667bf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-129' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-62ddc983312cc8dc325a5cd5;b32340bf-8c55-4d3d-83a0-7d58c093f6cb)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-130' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-401f4a8407b1f8d5163cce59;62431c59-4568-4794-91b8-6f2a637181de)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-131' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-51c0253653c8fd546e736ac3;a1595e2d-de5c-4892-94f5-7ad9d54e5dd9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-132' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-7f45fd4260fd06397b05a3b4;e71127e7-8b2e-441f-bfa3-03c330c3ff6b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-133' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-139852ce0d944f6f0f3b6193;fa719138-a931-4b4d-a184-0cec69927dc9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-134' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-7ce944161456e1ad0818dc50;4623ee10-53b7-43b0-8018-23945ef0b096)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-135' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-317895ef11fed7ba74b3312d;0a6705a6-46a8-4e9b-ac86-83d2bf71743d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-136' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-0287a3bc3d18c0df4821bd73;35e3e26e-bcee-4f4e-ac19-bf5b5df813f5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-137' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-35c6577c1401433f7d47234f;bb37e51f-0f2e-464c-9550-20d20629102a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-138' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-36848bdc17177ad647e23e8e;f037d330-cd95-4bb5-97e1-8707380a3a72)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-139' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-6b7b13a70987aade659d882e;46723498-1fc6-4cc0-91a1-7c1373ef0500)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-140' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-06c161ef5e2d51b568f3eb03;9fbb36af-1b3d-4e79-93ea-cce9431b5a71)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-141' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-3e64cd931dd95788673b6e24;77cf3280-2d1a-4448-881d-807e05d27e95)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-142' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b69-56a40d61035a415b479d1205;7abbc0e2-4e2e-46af-83d1-4c75b4801d13)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-143' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-2a65dd135b71ed9f2f0095c3;4739ae97-77ef-4a46-8e8f-553760b366bf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-144' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-47409b121c3296e02dfacb95;ab2a88ef-7660-4d2c-b929-d09514b78316)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-145' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-58bfe64e49363b405f315b7a;ec7bbd8a-406a-4ba6-84ba-63cee4bbeb8c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-146' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-0c25e334061f716f04ab7223;83bc64bd-64f6-4f83-96d7-0b0bc0aa8475)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-147' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-3de1156652c8bb06269b0a3a;71f03f2c-a45a-4b7e-9b35-027342aafe9c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-148' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-082e8e070484b6207934b82a;fe87718d-842e-4bc1-a464-1b44e0757930)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-149' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-2245d6642555f05c56ce2630;6559b632-10b4-4f17-a953-1f2646309e01)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-150' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-22db128314f6c3294a3e8312;49dabff5-26fb-4247-b095-f86763347f7c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-151' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-61f182713b9c928948a8e3cf;9df94f87-cc4e-46a2-8336-b16a1294f128)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-152' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-793c21681e9cae5177462e85;729f703a-df80-460e-97b5-e6a06c476a52)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-153' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-3b87799d08d0e39334f30029;dacffbcd-b8d8-4322-b4c6-4d2f24c5029d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-154' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-6c091e2007ce5a8335e43210;f6f6ff0a-0a08-4ee1-a5b4-34368941392f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-155' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-351838191541174c56472153;725d47bb-2097-467c-98ce-17f79b433f76)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-156' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-76e281af52c301e3573979bd;136bb1bb-6b84-4113-812c-19381753f6c9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-157' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-5cd484bf0440eab073d29c58;d3b899a1-c3e0-4a17-b4e9-50747b175e3f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-158' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-57d32a2b54337dc0212cdfd8;adaa2f7c-04ed-466b-b085-3cb03ff65937)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-159' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-3aedd7f3318d36613fe21fed;daa58917-0a86-4642-8b20-c1627f514dd6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-160' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-638dd4ca5f150cfd21ed00fd;1ceecaeb-ef01-4226-9092-dc50b82f13d0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-161' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-220150753c6deb293bf13f07;b7ae744f-7ed1-415c-ba6a-e13db74d8c53)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-162' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6a-3b31ff6e1ac6f0b42ebf7768;d70a0fa1-e8be-48a1-9ff0-af5e080e2b50)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-163' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-3c149ae668a65ad61f327eb6;c99e1fb6-28c7-49fd-8cf9-62a1c54f746c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-164' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-35e0c6ee555e3dec49c2e663;6078c9fc-ba55-48bb-8e8b-af54327651f0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-165' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-1a6037403b2fdc20425be5fe;a21345af-9e31-4a4e-b9f0-5f25d1620c0f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-166' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-476dd2721b14870a242d9fbf;6374d004-5300-4ba3-904c-3f0e89a4f85e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-167' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-125c3528681903790c2ed65e;b1f6da4e-49fb-4718-92da-cd047f0ac214)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-168' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-25be60dd38020c657ab3354e;fb003f48-2f79-4f80-a68f-04db1bbc5fa8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-169' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-29bb61056d53070b75dddf3b;62694ae4-91cd-4eb3-a0b8-3454f477fe07)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-170' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-5fbfef8f77cfd91040746058;e1152f0b-aae0-4f34-b267-31df6814da9d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-171' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-45cf25be462c1ad34d70ea19;8a64fcee-d228-4215-9520-16f234e859b1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-172' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-6841451e6c8ecbb3432886a8;3e415417-737e-4b2d-99c5-b5bcff0c91b7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-173' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-72abc4bf15dafcda33a77775;d677f47f-dd14-4915-ae85-549b5e3520b2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-174' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-7389345851257a452df9bb4d;c6f44e74-c1c5-4a75-8fa9-dfedb4bb3f7f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-175' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-13b0665e22b2a93b1fd19820;bb2d5ce9-745f-4938-b709-6e6feac74005)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-176' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-689a667e5a90ca7037e542e8;e744d357-c237-4d12-a12f-71a84d137f44)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-177' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-4d7600c07e28901b52ffe1e3;ccfc2026-5f3c-456b-8583-360331a21e3f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-178' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-13490b611f32c82705bb6d3b;9665917a-2bf7-4b31-a152-af0df21787ee)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-179' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-1302764e0820f02a135f816e;79817a95-5955-49f5-89f6-ee0754de0eb6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-180' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-03b8dcae47b30f951bd2b955;d7508d75-8a46-4be3-93a6-a3c53bdd91b6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-181' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-712a07615ee0d9c22aef0566;e1bc3099-11e1-424e-a0e9-7579bcf88939)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-182' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-3dcac6be6ee75548710d86f6;f5528366-e35d-47d4-88f3-0ad67f322dda)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-183' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-25907ecb66c1ee4104ad1b67;25170ed5-7cdc-41cf-becc-c7cdadb83182)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-184' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6b-70ac09a61e3b556011506ac1;3669e606-0353-4b03-90cd-08311873b2c3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-185' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-23d077223a0272126f7b03e9;7361d7b7-93e6-46e6-896d-b8aa22f69495)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-186' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-1bdacbf845c070cf229e4290;ed3adcfe-46bb-4b94-a118-18762439ed08)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-187' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-47915ae22d1701f179c34567;e6919717-4477-4600-bfe9-df2195ca7166)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-188' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-56a77d0f77db8b1d140f4b3f;6b405c49-44d5-4b82-aa7d-02ff8e37e6f3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-189' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-1c055f4a1c7366e536436c34;75dc5929-445a-45ab-bc3d-5e5edb59ea5c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-190' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-4994804964e01d9c2ce0e261;f0ffbc4b-9da3-4aed-b6d7-ccc4b3aa55fa)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-191' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-6536ad692cdd0b2a29e54562;aeb605c4-742c-421e-b1e9-7acb9d5ffb60)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-192' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-4d0f6d0124a8393951901ed8;e43708d9-f888-497a-bb37-8892f3c8aa65)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-193' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-3856fed802403c717b69cd81;b2b15dc4-cf69-4312-91c1-72172284c668)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-194' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-741956f360d1e3c851264a99;eb76df3b-2e94-48c1-8469-8af2bf0649af)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-195' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-43609d5f25c57b327b98ff75;daf4085f-4859-4918-9aad-a5c8ca8a0e21)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-196' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-38bf93f9489af5bc0e3ada32;9467fc47-7dde-4dec-a90d-42f162de3e34)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-197' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-36053ce77ef909d86ecf81ed;ea57a6cc-5b31-4621-9c60-099367ef0f95)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-198' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-41a9171861d9f806544fffd8;84975dea-f91a-4c68-84ea-14df4f886219)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-199' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-128759da3e47e3032fe3f5f6;ec579c0c-2188-4800-b9e0-f9d0639fafbd)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-200' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-18a5412864f09c7908ccd294;a29aab91-37d8-4bf7-ad69-5e9aefc1d7bf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-201' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-2bdb2c8d219154fa1168579b;4efa57ff-f3ec-451a-b0de-f52c3580f2d0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-202' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-6df32ebd63835e1a27252669;d0fe82bd-0b84-4582-a183-749b438c5f0f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-203' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-6437cf980468f945227981d5;8b2c8f03-17d1-4a46-a2be-aac96e3902a8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-204' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-7773ff5a45e718bb7c597e08;948b5f46-67db-4c91-8dfe-346cb37a7a52)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-205' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-64d26e9542810d2e5cb56590;b0d2eaf5-f01c-4397-a7a9-da94c8538194)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-206' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-0430995e1638d63d4228da9c;674ba6e6-5636-4735-88b3-3fa1032198df)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-207' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6c-00375ab776d64b87470a08dd;c20927e9-d58f-4812-9377-274b5af0388c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-208' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-43cc9491557b7c213e27e8dd;0c861e2d-0405-481e-933a-10588e500fac)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-209' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-6b70216f5b403969109d7043;b1fbae3a-65cf-4c88-9536-e48d821eed32)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-210' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-029f3c005bd62f9579070302;71f874ee-0ff8-41ca-be58-058d622c403f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-211' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-5aef722103968b447259c20a;ada34907-aa25-43c5-94d4-7dd61642220b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-212' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-541a27f2170dfc080af46155;bbb5ac7b-f230-4ad7-a90f-dcb1dabcb3cd)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-213' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-79cb63745966fbc6356aecd0;757b6d12-1333-4dd4-871c-2f6d704079e4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-214' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-238bf8bc21e69a49584c90cd;78b12e7e-c621-49af-abea-2699667d478a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-215' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-3763f359036ebcd806beb55a;387952cf-452a-49dc-8678-ae8161ec37b2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-216' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-7d5d1fd41612cad30a17a38d;48a6ba0f-20f4-4158-8f51-020de5ab8afd)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-217' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-1c2fefe909314cbf4709ab09;d12bc77f-545a-442e-baea-6631a250fa35)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-218' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-4416cde6379b931e2478ad58;b0e16289-e0b4-406e-b11b-abb987706a23)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-219' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-5e0dac403f80bddd14f55bbb;d557c3b5-9a18-43d6-b081-e4e886be1092)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-220' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-72d8b58169959f3f4ada3d97;aa67384c-4f6a-4220-962d-c13b91feca24)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-221' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-14725cd405f8145253d04207;2d68c29f-e69d-4560-b7c6-2f310e90d0a3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-222' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-29d7490106270a356f25549c;4e88ad56-8f22-41b5-b2ed-b21312eb4432)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-223' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-2b318d772b5a8ab82d3f685c;0c7222c5-5ebf-4d8c-aeaa-84451a0077a4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-224' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-5efe39e959d8f14d7e735541;883df2d8-812e-489b-b0dc-72c0273430ad)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-225' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-18074e3d5e479f4712d82ff0;6a93512a-8411-4b2b-aa4f-e72ef1c02c67)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-226' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-6b86074c603b08731834da46;c0a04d90-d384-44c0-9c31-3bccedf29cbf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-227' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-2f16695773cb9d8c7ab403f2;57eefb8c-60ae-42bc-a7f0-1729d70bdaf6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-228' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6d-1525656d27180a5255b1cf2c;9b7976a7-b3e6-4861-9ff9-cad9d0a62498)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-229' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-0428119b50f5a71076ba4c36;67ef1eae-ef37-4d7c-9b44-9245f1d903cf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-230' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-55a62e1275257cf3291941e6;83a2c121-c76d-40a4-8846-098e27a0aff7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-231' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-0517d6c72a38d48f533a1f80;7b6ef9e2-065b-4b61-8eae-7bb84b3ccb12)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-232' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-17b30bf2730ddb6b6406df2d;00f2c248-f2d5-4c00-8d30-f192205c366c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-233' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-7d660dfe590bd1321ae15f94;b19bfeec-cb85-4c80-8283-90fb279917dd)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-234' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-2d2cfaa13d9883e10568109e;27f81be1-5fa5-4edd-9c30-e024fbd2bf94)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-235' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-5e9a5c24470c74e37afac41a;e8ad3a97-9554-4d17-b01d-ff31f9c926e4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-236' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-3c0e8efc070c30027a3bd538;59c5ea8f-d9d9-46e2-840e-df7b28171952)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-237' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-4959881749b70fa4521d1f1d;ca0281df-85ce-45a1-b20a-64c99f48d39d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-238' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-6e1c971b1dd48b0d7e92a9ee;2ebcc2a2-e7c6-491b-b432-8a38c20178b4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-239' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-28ed43db693524371015050d;ee6529d5-b4a7-482b-8a86-fca2bb61213e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-240' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-077f80cf0d22a13a16311d4c;8c56d510-f2c9-491b-bbca-b4ea2f738953)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-241' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-28beded56291e2d92891dfda;d9a90cfa-046e-420e-bc84-def324754149)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-242' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-33a95a346e82e6577c2a315a;d361b126-a435-48c3-b040-d4298a6a648f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-243' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-0fa3a46724c30b4006aa496e;4fe05b6b-3dfc-44ca-80f7-735bdb1c76fe)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-244' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-0f89c7592501e1fc284241cb;03f12efd-abdc-42e5-a299-5e1ede818621)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-245' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-5bd8ebbb6376449b4573cf4c;8f6f666d-3457-4423-8256-72ad00f5400e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-246' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-207477400112dddd1cbaa639;15e5e830-1414-407c-a4b3-a947fb6201eb)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-247' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-57c9cdcf45868a8406ed5832;d733ba08-cadf-4ce8-901a-a79a342197d0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-248' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-2219a9337b27cbd26717b9a6;38842558-9adf-4714-a244-a875af72b4cd)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-249' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-6738ab80600da70700a91836;23812508-2eca-4f51-a603-b2cf0087b515)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-250' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6e-2ff9682e2b647f3c1a774d02;7be8d696-133e-491b-a9d8-713c5f7b8dd7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-251' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-4792f19d5c9df42e2572e38e;24b8c65f-c11a-43c6-be06-90261fb81793)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-252' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-225d34e22c8e1a6b08c35c89;99b0f81d-0d53-4d03-b712-2e0ba39ee870)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-253' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-338421170f027fe35292788b;62a8f8aa-cbc6-4eea-ad41-819b67f2f6f6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-254' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-786ddc586e74bc8f4c72e5b2;89c88534-1f32-42b0-a071-b4d75a3f698b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-255' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-7b8a66447353ff4e7b83e07b;5b81f23b-600a-407e-8075-2a2bbfbec618)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-256' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-6530f18559fbe6a6335f85ff;21c15efb-a695-4ce8-868f-a8e9affdcff5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-257' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-7da038ba5329b5dd61dd7f9c;c87e9def-12ed-4912-98d9-188c01c0e39a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-258' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-2457d8506f318c2579e6ae98;a772bdeb-8821-41ad-8091-60b211a47c90)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-259' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-365a577c5045e74d047e298e;9b358159-7d7c-4564-94b6-7d97da58f0c0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-260' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-04ee9931116000707742b542;b1d153c2-208b-4ec2-b05f-55dc01bd5395)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-261' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-621221333ab26b5c6a17608b;a482f8e2-7a41-4a26-8281-7fb8eb141720)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-262' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-4d4fdadb1e1d85491a394919;e6d0e575-3826-43e9-994e-e4947c48ef29)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-263' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-5b13728c531b0c1b6e732219;172a08cd-6bb9-4736-b1b0-3d906478f79a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-264' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-3e8713a17cb63e7369727555;e1e64fdc-69e4-4532-a5b3-274b5617189e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-265' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-425e3af121f1350f6c0a1e00;9640ca65-f139-4b66-99f9-581098355554)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-266' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-3a401c5a1b7d96ce107ce905;7ebb1390-c8e4-44b9-8fad-5b04f7f67c17)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-267' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-59b08ecc032c8e6e1bf6b1c8;c76bd2e5-463d-4ba2-a6cd-1da9663ba2bf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-268' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-32dfa7e240e2f0f151473c8e;f966dab8-9ce5-4ef9-b70d-cf7e2c87f180)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-269' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-7abb44fa563cabc24ee676b1;378e363f-cba2-4b07-8d31-04324971780a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-270' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-62f4f56a368c135609f76f6b;c7d8c285-4f42-4927-a373-49fc475165d2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-271' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b6f-2c20f2bd764cc92f4263c081;7c6f360e-f1f6-478a-8530-2d60dece3c64)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-272' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-6f63cc272b9363a048c3d8d1;2de0520a-ac25-4e29-aa3d-dd8a0d9bb999)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-273' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-06a0130e3c13a4f77e4d0a9b;ef0efc45-c5bf-42c4-b4fe-1301f8dd22da)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-274' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-7742945a05254fb026dad43d;075d46d6-0d22-46bc-979e-f4ca6427e008)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-275' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-1e4c2eb12f52134311364f09;e9130be9-7ff7-4750-bf2c-097a0312c09c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-276' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-32aec8394ea7e0d119453bab;28f8cc7e-b2ef-44ec-8cdc-8be6d3d40d83)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-277' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-7872d9604177db191e474367;7cd8a834-93a7-4b7b-b181-cd1dc1fe73ec)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-278' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-529aee491825d010173523ab;d75554c2-907b-4e32-a2b6-a0033b0ef280)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-279' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-224296194369407a35fdb10e;3da72361-61e4-4fd6-a96c-2ed12bf5d65a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-280' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-7285bdaf4f31eabb58388365;5e793b38-4759-468f-b76a-832d02ebf9aa)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-281' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-223ded5d11e9195524639d4e;2164d799-0f55-4596-bbcf-b2daca32057c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-282' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-3fcb24aa0827d6aa41ea8c12;be27b75b-bb6e-4f3a-8e57-5562ffe21fbf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-283' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-3a39664e3f5c0b050ba78314;1a10550b-8a96-47e9-839d-2e7f888231c2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-284' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-7c9b955b5b0aa9d059b2490b;01d1e248-09ce-4bcc-846c-d0be0204d598)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-285' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-7f4f30056ddea8d37f231975;e1ab6cf4-213a-4e31-b7c2-09f437f994a1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-286' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-3fc70de86b301fbf604a7065;a915182b-5b95-4a9c-a41b-92e6041d83e1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-287' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-1ee4788261ef7de66d074c36;fa1e8f4d-e273-41b3-af7c-b656a37112f8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-288' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-0e2a6b9f24cc918d171b9f65;9bf0ddd3-0c86-4ef8-889e-ce50c6ff0a93)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-289' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-2551aea2559f0bc04a5cc17f;7aa2ed6c-363e-4087-9c5c-b386e61e3f78)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-290' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-7d216ec7042b7316115eb8e5;61469f3c-3afe-46b9-83fa-699b63f6a804)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-291' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-476910a345d7f3aa6c1a6ea7;cff93fe1-7c0e-4bbd-85df-c1175c8ef0ae)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-292' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-0547fef330b27c5d67f499e3;6a2da494-ea61-42e2-868d-a4507e43785c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-293' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b70-06720e6a65d5e6d306689599;c12a4bcd-606e-470e-bf7b-db25664002af)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-294' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-0c78b43245f463f254c1e166;6dd89329-1996-4234-9b77-c02ad111d4d0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-295' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-18f170104e4bdbf641f85e3f;a6286114-ecb9-4f69-a449-f548a48f4557)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-296' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-0f21d7ae4ed2507c60a54fad;400aa4ab-f9d6-4ebe-8f03-e21ff0de1eef)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-297' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-3f4b9bd338cf8bbb60027f93;33e5f3e7-192d-480a-a3e5-65b9dc9317f7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-298' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-48510337592eb3a537dfab22;0bca082b-f784-410c-a8ac-ff4b9a6acbf0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-299' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-00cc5587569bd68a5e2b60d9;957571da-4c81-45ae-af39-73ab41e0f51b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-300' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-13d8e3fc6fef33980a91c73f;719e6c50-ebc6-4df7-a7e8-d61471a05c8e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-301' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-4dbf5f4000e276470e448fb0;0d8cd516-6b94-4a20-8a36-ba028c189da7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-302' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-0d7c3840700d5b9b4a2cab4b;52b3e4b7-bda7-46db-be7c-6a190f52d996)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-303' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-2df8a1d02aa217c630bd0162;c395fcbe-f33b-499d-af81-b2e2a358b5d0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-304' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-45d18e6407c57dc121cf8ebb;16edcb7c-de02-4b5b-bd83-fc6285b0f928)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-305' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-2ad41c473a2f5b7a29659ca5;b2fc84ac-79f0-4df5-aecf-2d7ca0d7b074)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-306' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-56467e4d188664777144cd62;3659d556-c114-4225-8e7c-ab4d8c070cba)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-307' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-3184b8284b621bb95436606f;cd93f26f-15ef-4d68-80cc-89fc23b0503d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-308' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-0e000ccf0353f8b409b45eb8;435260ac-fa5f-43b1-a782-e31598de866f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-309' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-213763284d31c07f3580a37c;893731fb-19ea-4b9d-8981-131bb187d0f6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-310' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-436370c46cc38fb464eb59d4;25b65489-1df0-4e34-a68c-87a3d245c8ab)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-311' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-4234744a2ed8898e28824870;ff800c4f-7953-40dc-92fd-ca5c6af9f631)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-312' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b71-630694be6dcafe17246f6d4d;a426de38-cd53-4f5d-b2b2-8cf6a9d48f69)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-313' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-4f53d09a397e843050aefb40;c301d292-5a3c-4e0f-9992-a6a875084683)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-314' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-377c694b24cce16a7bf50980;39905b83-c7c4-4e35-9dca-367b6f6acf19)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-315' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-76fc188d198fb18b6246e21f;807849ae-0267-4d7d-92ac-705ccc0d0c4c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-316' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-387e58ed5c9a9e4e5501dcd2;289b11cb-ba7f-455b-b5af-f3e7da7e8bb6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-317' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-139c27390b46d5ee09ca72b0;b09e361f-1c2d-4ba1-b005-aed9b76dadd2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-318' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-6f3561ed5025b85d53988972;b72f1514-b4da-493a-be6e-6c2443bd4c70)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-319' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-110ab3550fc265e11a4de68e;00d7376b-90ef-46d1-b6fe-9650bc395378)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-320' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-0d163f9979b4f6041d260a50;9507b0b3-5bc2-4c48-b018-a3a2e140ba85)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-321' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-36178b296c24f81248e66288;dab38f7c-1a18-49d1-8182-a3838d374a61)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-322' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-12508ccd0f3f9fe219dc7c6d;961f9552-c158-43a1-8d98-fdfc06bdeee1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-323' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-4c53755048ff33a157f7ed70;824328f2-d05e-459e-85ca-adc7a33ae977)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-324' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-12ec1ee10e98b39e1217b7ce;24302e05-800e-4c92-bbbf-27e56250ff26)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-325' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-287af994237bceeb2bae3316;e718cc5d-23ff-40df-acb3-a24a607c31d6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-326' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-22cfdd9d4b434faf5ac957e2;9ff55da0-5637-409c-8afb-57169418ce7b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-327' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-13cf0e8a668dcc3a5f4626bf;a907df57-5f4f-4116-954e-f5d93cd30ad3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-328' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-7e8e4c452d4f7b18434c6750;e78a77ed-c6a1-4196-b6a3-8fe727337cd9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-329' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-411feee629e14df71840e85b;6f962f17-ccfc-477e-8b33-b2314a613493)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-330' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-35dab4e44bb97e5102560dce;b39b9ddb-6743-442d-90af-6e806328f5ed)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-331' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-4306080b00da8fe55d588f20;160595f1-482a-4cab-8094-afee019d520c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-332' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-05c154e21930e4b7026deb7d;c284dc8b-39f4-40f2-8464-4f6916d53b1e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-333' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-4bda12ac7b14a9cb10d16255;27ceaea5-b66e-45ea-85c9-97d050c53512)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-334' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b72-07a7d2e44ac98c5355877dc0;b2250bbe-4c6b-4ad0-80f2-042c101d7ac7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-335' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-116a6eda736d4b46648baa4a;fac1cbb9-ad77-40ce-bcaf-0f143d2ff5a7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-336' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-3769916a4713ac004fb2eb1c;367645e2-b4c3-4a1e-943a-97fdc880f54d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-337' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-4795ab2d750f07be22c447d8;f30f9833-459f-405c-a3a9-938cb6c23a71)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-338' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-316a8cb3511a3ee55a3511ac;a1d2f8d6-fea8-4f1b-abac-8f4059f46396)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-339' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-1dfa5b4d510d88697289496b;2c52d7f9-37fb-4782-a659-6524ecc102db)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-340' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-31a0e55f54a79a2727813a68;72ad8c58-cf96-4dda-a168-119980387c72)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-341' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-6cc72c31347b934e7305684e;7b2b8a89-6fe8-48ca-a55a-ce863a718c59)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-342' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-47eab5832cca760146537c73;e47f3843-ce5f-47d5-a0a6-c80c4ae96306)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-343' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-6eb5d0ca3c8572507814881b;0a3614e1-6cb5-4b1f-8fbd-ad4c9a03b853)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-344' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-6e80f3d611fba77a3034413c;abd295e2-db73-4339-baa6-ab1664019cce)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-345' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-69882b0119f5b807019b23a3;31b3afa4-453e-424f-82b4-d71c413b093a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-346' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-602a77f7136b63f668a99d00;7b8bc834-70dc-482f-934c-5dd3a8e43dc5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-347' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-7e01254163eb57a53455df6a;51f2afdf-3481-4c06-88e1-3c5c461e5493)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-348' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-6843bc570c3c92e4310872b7;1af51e3e-d949-4b2d-86bd-790e597f97ab)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-349' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-143633b4580847f950901a4f;f751f15d-b36c-4344-ab09-d04ef2a3149b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-350' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-08b1a2bc6678be4b4e3d20a8;4a5e660e-63c6-4fed-848c-c5deed54f2c0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-351' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-3a9a4c544381f88625464896;3798d7fe-92b2-435d-9477-d40fd901452e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-352' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-72e8c427454e82f0112e9d0e;897cc36c-36f0-4dad-9e1b-85a02cbd3eb8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-353' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-2e4e7c291716cf0850b12f15;2345266b-015c-4e9b-86ae-ddd61cfbaaab)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-354' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b73-08686f485798b32b507a0a55;cf37fae7-98fd-410a-80b4-7f3dce053d93)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-355' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-2eaf7adb47836a4a33dc648c;839c1ed5-e7a4-4c64-81ac-433eb9b38e7d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-356' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-7e6ae9524134db264ff04c71;05368de0-be55-4130-933a-9d14a5a0c548)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-357' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-7464bfec74160cdb65335311;f2ba2186-730c-4b49-876b-f1ba7ed26839)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-358' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-1abead997817da7e42cc8178;006035d1-bf5f-447f-88a1-00b701c15d65)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-359' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-1d1fc9f8289b2cc136d85f2f;8c9b45c0-3bdc-494f-981d-a55a78de4802)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-360' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-5da148a01c0a806826976c67;1d1ff8b7-f1c3-4fc1-9589-08f124cee630)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-361' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-629b87ab50b20c58616ae0b7;6ce64547-f78c-49af-937b-99edbc2a2c44)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-362' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-7769804c6582bacf77b5123d;4be1e2d3-8147-4764-b169-e46fce221a19)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-363' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-63a0cf7840683dd61cce7488;598bddec-56d8-4949-932f-5f07127c7601)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-364' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-286fc2ad300a5c3e7aa0a703;cbc229d1-a0d9-466d-b091-56cd29a6a95e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-365' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-1037dc5c403f283c0b8047ea;b7fa38fc-b748-4924-bfba-168c89cc839d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-366' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-37c71a887179f2c92848357f;74c58f27-6fc7-408f-a6cf-dd6e47dc667b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-367' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-2d4f5c811f34dced5a91b085;f3cd3d88-df4b-430a-89d7-39a32eac76ea)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-368' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b74-5d6e8d545ae02b820c1cb700;a6aa6ea7-fe46-427f-9970-fe1206f25f22)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-369' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-2a2d206109e356181ea05ca3;d02076ff-543e-4315-87cc-ae97d267854f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-370' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-4aedf3d44c9f0b0f1f5d4d08;a23e439a-53f7-40ad-9a83-98d645480916)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-371' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-7eca3bfa26d0f89c5cfbbcf2;a89e1bfc-962d-4227-ac15-037e0fd962db)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-372' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-1885cf5d3217b0c0288f0dc7;ea308230-830c-4131-8c5f-d9ec6209b433)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-373' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-18d3084a03b9322e39a1a0d0;617c0a8c-c7ef-4c36-a6e1-926e6fdb2632)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-374' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-287060bb4213412b6bf6badc;1242e67f-0a97-4cd9-a735-911247fad8e6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-375' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-62f4b3823dde822d7c9c2cf4;0c6ce751-a6e5-4c93-a113-f6d3a79e2744)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-376' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-0ec8b1094fe6363c5dd661cd;4298a021-d267-438c-a124-762227efff03)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-377' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-5013c9bf1dc039b114a13421;64553373-193f-4df9-ae00-74f6e8628bc5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-378' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-0c1860bd3b1c39d76768a4e0;c1b13734-6e9b-4077-8232-4d887a3c7e1d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-379' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-3964ba0433f6db8676cee68b;54dc147d-fefc-4364-9d23-d99bb8031f1a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-380' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-5c033a2e29ac1ae120033d71;4643250e-ba0f-47a1-b217-18a2fc631334)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-381' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-25e6216a1c5b28272952d995;cff9065a-f90a-44c1-97ac-f51ebea6414e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:09] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-382' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-79cec5e471ec6d5d361d3982;4df068e3-2c17-40b0-a567-3e5318e3b80a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-383' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-0b80b19358c7e1ec6ed5c409;eb19f49a-f243-4eb6-841b-3706805806c3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-384' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-75a57a38434e5efc05dee7d8;36f8b9be-aafb-4a74-8f3e-8a1b0eed19e6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-385' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-39dbc2e9500400366bf059d0;a7962797-104e-4506-bb96-61f9bed2fa50)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-386' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-5a1dffe83ea99256734d2955;13d4609c-2ffb-447c-8d0f-c54c6dba3e8c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-387' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-31c3b85c331ab4fb67a40d52;b11aa1cf-63fe-4416-81a6-9e7d3a77d6e8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-388' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-06f82a5009b256130bd7e0b6;ff45b6ef-1587-48f2-bd53-5abba4d9bda3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-389' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b75-139cad723da3d65175345f5b;89f9f146-58d1-4915-9d96-3b1d5acbe76d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-390' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-6095fb1a2c73c2355c1e8bf1;1a34e0e2-32e4-487d-92c8-3b389daed132)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-391' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-33d07f13432b8d8471ded252;5708b5c3-ace9-4593-87ec-0167d128ebe9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-392' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-63d86774675fc3c9011e2a86;56796ede-0f45-4870-86bc-46eaa915b546)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-393' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-44d9b800735438346bd74a35;597e7d7a-48a6-4778-80dc-2f4cdc3a797d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-394' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-27c0cd26507bd34840514ea6;be741dfe-2b50-4b85-8338-12d552d52d52)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-395' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-4defc646106992ce7282cd58;bdfba306-c466-4580-8965-b574bd82e8cf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-396' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-27f1001035093d497360c207;bcf9425b-d8d4-411a-934c-af6ff45ba1b7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-397' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-2daf8b562030044c6c1009f0;74116d50-7bd8-42e4-870d-980b8aeae322)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-398' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-2babf2805f9c81fe7f0d24a2;79eb9106-c8a9-42e4-84c0-6eddaff26a9a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-399' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-702113b13e65449b79ff5695;a8a8a0eb-3329-4dde-a09a-083e66c01c49)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-400' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-3706497c33e646af05e45b91;8234b4c2-1b5d-4d49-be50-6e7c9a549f7e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-401' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-7fe94f4a379a9dca31d64ece;eb96998d-4621-463a-964e-6cc59a015cd4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-402' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-78058b4558e90da0760d9b9a;6436ddf5-123f-4fd2-8933-8a1a1a810067)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-403' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-6c7f06055ec9621c2051aebf;072d2e0e-3c31-4176-833b-c0619c8cb060)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-404' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-2d0ef3615a2828f95850723e;5595a4d3-c76f-467c-b0b5-9d3f223fc7cb)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-405' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-4604047052481e92305b263c;57e6b2e2-3468-45e8-b5ae-050de90ac314)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-406' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-736a5178398beb5c4234194b;b8983ddb-9f36-4c80-883a-d29b22e7affd)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-407' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-78bca8e2159f7f1041af01d2;7c3393b9-fbfa-4226-a99c-9f870f2b61d4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-408' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b76-46822231059621f5025b6980;935f14df-a2c1-40cb-bd8b-9e3451cd3042)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-409' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-125882cb5248ccad6b83d162;54c753d2-cd9f-4c53-b44d-cf80d8a56994)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-410' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-36e01f4a45789ac1053d1fb2;ce51ba5f-d2f5-4e92-9eb5-637034d59317)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-411' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-794df87d2c66592e1eff0358;986873d2-85f1-4b2f-8f6d-34a18bfb6870)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-412' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-77fa4ec1551499c22eec6281;bc7a0ee8-da1e-4541-be0b-2665997d4276)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-413' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-62aae650711eff457adfce05;da55ef7f-89f8-4689-8df6-fbd7fd5cebe4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-414' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-2fcf4b5f1bc9ce003c5d53c0;f281e8d1-bd68-45fc-a619-fc34eca85b25)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-415' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-2877ae2a7f1c37fa7a3e3980;39ea6e00-38ed-4342-a9fa-842759a16c6e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-416' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-29edeb58187711950eca0bc2;7a628766-ff10-4746-bdf3-ea184b63a7fe)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-417' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-1c91640e14c748bc797c6f54;db21f65c-0753-4c09-b5d7-868a2c36315a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-418' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-165dbda4152914fa2004f8a4;b52bd758-3dec-4293-8a63-f58b9c51d382)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-419' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-2ea397542d2ecb562a3721bb;de172205-9ee3-498c-aa51-bcff99de7c4c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-420' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-15729b2531da54b215b7cb96;1db88084-17c5-4cf0-8db6-370a93b88b60)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-421' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-51de3c625b694aa30b0cec8a;20a7f8a3-b0ab-4f45-b1d9-416bf41bf52e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-422' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-5f9f5366571155403308208d;2ac1af90-6a27-48d9-a6cc-7e2c0aa6426d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-423' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-0a2729ee7280c34c3dfa4f49;301792db-e863-4b2b-a6bc-caab374ede96)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-424' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-0d401bb24bbbffc776367521;4053be02-620d-4c88-9749-90aba8963a63)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-425' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-15a16cdc39f1e6ed58b8d77c;da90f41c-9edf-424a-885a-6649c3dbb811)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-426' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b77-7e3b47fc27be80d87bd11437;9b24f6d8-1137-431e-a134-dd3704afc57f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-427' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-6686bbb344bd6768666dcc84;9a9f0392-5b18-4f5e-a6a6-6b5123768d47)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-428' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-1797b72c6274c827398580b5;547027a1-e799-4c88-af4a-ce361f90b08f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-429' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-0a9a37d65b65b1f94fad93f9;50e49f17-1d7f-4fec-8367-8c49a3a8e320)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-430' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-4990632b4fcd56b902088715;e5dc98e1-3ede-4b58-9d31-dbe7a449700f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-431' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-575286ce4255223601c132ff;bca6cef2-6854-4ef7-ac7f-415e31e0af4a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-432' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-379305e54c2a95817ff9335c;4cae3d56-9c16-48ef-befe-36747717f6dc)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-433' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-4f63a26601a139eb73a2a6d2;8208eff4-f6a0-4f30-b138-b6d1a536d4eb)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-434' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-4ca2a5dd650c4da821e806da;3f9837e5-abec-4fdb-9929-05d66dd1fa59)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-435' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-7a636b464fb6dee220d20d51;e14f6639-f07b-4c3b-bb4a-3d506a7dc430)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-436' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-3ecbc7d24bd6223f200871ac;f57559e1-7a1a-429f-b535-6b98346c32ff)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-437' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-1b1517501bbd49d100638270;7c25d1f7-dcdf-4442-a58a-98f8ee180ddf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-438' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-33829b7209c8bac839ab6185;8769946f-bbe5-49b8-b717-e2c5a59472a7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-439' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-033bd4703f2b6f53223a50a4;b740b799-ee32-42d3-b6e4-3a6e80323aad)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-440' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-0545b4742951168e22e29987;2b853dce-6153-4e75-9068-af789ad20715)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-441' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-71a5c754057ae5632000cfa6;f7b87d1b-63c6-402a-bb8c-ef9dc9302cde)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-442' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-2ae150d5300ac9a41cb6f3ae;5411c7d0-31ed-4d29-9ae7-837bc47de557)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-443' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-2773f92b04d7d2746ca507b1;ffeda171-2548-4790-ac04-d1a40bffd7f4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-444' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-647295c03c752e3c64c87f85;3d00f9c2-ac32-4173-acff-afc1d9591ed5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-445' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-7da3556d19f7b3de42a46f60;31f29b42-c1bb-4f60-b8e5-b8447d10184e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-446' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-4b6199a40bccffce11e4671e;0784ca7a-b383-464f-948c-e7111b14ce2c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-447' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-01a885ea67e0f4a216f13d05;31ca8de1-1fca-4f47-b3b0-3a5c02b7c8f9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-448' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b78-160094ef450401c35b14770d;3d70b422-b116-4fef-9460-7f418cba62b2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-449' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-0cb3008f76577bac3d723d45;c0df12c9-4202-4739-b965-6253439a5591)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-450' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-08804edd7916ae186a18bd40;dacbf9c5-3e29-4d14-912f-926c9022a415)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-451' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-1071602814fd87634489cf9a;8fdcd185-9935-4706-a784-dd49ea6a0ce0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-452' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-697f5c5d095219124d8f58bc;c7c10ec7-d8d0-4993-81f1-42fded008d7b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-453' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-14be7fc3448503e9149184a7;312cf850-9ea5-488c-ba17-0dd1362cb2b4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-454' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-3206a63f631ffd99270ec141;4ed544f1-a586-433f-956a-38a44bbc3c08)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-455' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-6172dcb9736da4370282f84e;dd6dad84-182a-49e4-b29e-324c14caeec3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-456' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-5d95294166ec8c6e15db95f5;b4d8d352-1578-4ad7-b1c8-b378ae5c25ce)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-457' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-5766c9086851966d32dddcdf;b5f8cbc2-7180-4454-b039-9b85e3d9f19c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-458' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-29b7844e2c71ebbd38002994;27111e58-e284-41e0-860d-de989f5ff880)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-459' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-498d79fa11da3f2a200d2dae;a1a4ed9c-ee77-4273-8fad-6552096886e9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-460' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-3e166a7f53617dfa1474a6da;5fa453d6-5bb0-4b0a-99dd-4551edbb6580)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-461' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-3389b4b54890a7e01cd2c9c4;dc7a2dc3-9582-414f-ad68-025ef0b11aa2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-462' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-7d10d494580ac17d29faab68;299c7458-b88d-4834-9125-029b93721496)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-463' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-0a49f08e02f64daf508f7414;b6c4f862-1f02-4a08-bc1f-1caac957fa1f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-464' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-12c9328326bfe1a762bd909d;d81cafc7-a652-4a25-84d1-78fee9e6ebc9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-465' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-4743a58052aa6cae30d71a48;6a85d0f6-1d86-47d3-b9fa-c4e97a6ae7f9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-466' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-23303ca7341e0ee237bede8b;ff005762-4aa6-4afc-8e0b-38733869bc47)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-467' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-6100c9fb6b00efe0705c35cc;1ad61a94-9b4c-4acb-a681-425f910ee762)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-468' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-199cb57c463d941d535439d7;bc71cce0-03bc-4fd9-ab88-ae899b41f105)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-469' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b79-30301d80165b736c0f3d4ae7;7d3aec71-0568-4b8f-a973-d4d4d9927544)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-470' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-6b9197ee4068168a5a3b48dc;97ca6e98-842f-4205-b918-14e6a0a02577)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-471' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-7564a2cd774df47a007611f0;e325a78a-033e-4f0e-87f7-db8aedbbb09a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-472' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-674510e15516bc8064f72d6e;c7aa3b64-c8f0-4f06-ae32-97b2b2855376)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-473' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-3b54c5ba655f5abe15560a90;24e9b16b-eca9-48a1-894c-9da66669db38)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-474' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-5ac25c627345f0da265b4384;3e7a7c90-e082-4554-91f2-ac0f8c432f19)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-475' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-2797268364e4f1bb6a741a72;3b7d1819-1e50-4a19-8604-71ba07c2c573)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-476' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-5f0dc05776a8701a4bc7e698;8a619306-a74a-4a3f-b54e-1eba976f2ef5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-477' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-19b444a46207f19817790fd5;65a9f0d6-feb5-4529-93d6-888e886a9efd)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-478' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-01971ec86278c823796890b6;5dd0a49c-857b-4a28-8cdd-c557ee4b072f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-479' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-4d0e32ec523832a742c9b58f;5bef75e5-7b1f-4b94-aa18-933a79cf6dd7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-480' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-62c8be2102641cff4fec1036;0008f0d9-4686-46ab-ae52-24f7fccc875a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-481' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-3ae2fd5a06d42919556107f8;0c8b1390-13c1-4d47-8cf0-2836633832cb)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-482' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-0466b2903adefad90f2e9b4b;f9fbfa89-110b-4644-a61a-71654deccce9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-483' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-28fc72831269fd8f5ff7def7;5c6c57d7-024c-4f01-b360-32cb1c5fdddc)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-484' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-22884f4f0601c6bb1f10911d;f5e98e17-43b0-4235-b0ae-bfa5bb4caa65)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-485' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-686da3ee5596c60a56bd75ea;1e489e5e-6b15-4493-af4c-4995dd6e306d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-486' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-0ee05a8747c0e714553bc012;9b19fce9-712b-4d4a-990c-4ee76c2afba8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-487' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-5f7d2cca54ea59a53eb9310a;cb81efc3-fb09-4fae-b7ad-deb0ca2d5ed7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-488' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7a-2d1fc3340848cdd252a89203;da857902-197a-4b13-917a-c151ed3cb176)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-489' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-7448c6cd6e6e183a2898f49a;5833dba8-0163-4c30-956b-c628d797f687)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-490' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-3bd1fc5324bd5f225eb8c086;281adf01-862e-4003-adeb-2e4741bf26a0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-491' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-00e9bb572c18ddc53ee5f353;f7538727-96a4-4cfe-8f61-f27269491e93)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-492' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-0ce2750836ff3faa19f17be9;c8dfca11-cbfa-485b-ba08-f63ef6887fef)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-493' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-679bfca721b302b51d738f16;074e6448-946c-4aee-955f-514dcb44f261)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-494' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-0fb87eea463d4b2471ccb63c;279ae31a-c419-46e7-b51d-b26190284aa4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-495' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-7ef14f401a1143436c0d4005;7147aba7-c0ad-4be0-9b6d-e3d0af2e853c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-496' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-266082934f3cd2294081fe4f;08ab1685-8441-4f47-8c52-c5584cb28f31)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-497' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-6d071e5226dafbee5973ce7a;0bd3b0ba-9d3e-44be-b65e-a180ce6b40b6)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-498' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-67069439407d65dd0a092ebc;5bd4ff6e-9b3a-4def-8a81-34a3ad26e719)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-499' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-201aa07c31d8ce89150e1ddf;f44e1e0a-46ff-4690-9a9c-219947efe7d5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-500' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-2694ce477a88f29c698786e4;d945971e-4e41-4562-b072-093d30dd2ceb)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-501' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-65985edb6380401954218698;548865cd-25dc-4224-b3fd-f04e6d892133)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-502' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-5e471d9923ae8e4e7a8b7e7a;1f4821cf-6ceb-42a6-bcd6-0b997fcd23dc)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-503' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-0871a7d007347af00858faee;4faa3302-2d26-42b4-ac0b-7ce6a434b451)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-504' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-6bf82e1646de579d7235e82e;bff582d2-5f8b-42b5-bdbc-19b5ed957dc2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-505' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-7318f1733340e382182d5602;efeeeacd-a4eb-4122-9024-84d6772f7052)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-506' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-6e9e99f97d6d7f5c09a4cc79;48683188-a2ad-4a7c-80ed-43778823828d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-507' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-245e894b33990b792dfdfda6;1a330d63-5233-4e70-9cb9-771dbef5a6f5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-508' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-37db87580a5ae91f0ff029c8;94e60f88-75e2-4203-ba4c-23932b3c043f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-509' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7b-2a4725fe3138ef2a37595517;8101644c-7b00-4218-a273-6f3fdc24836e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-510' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-38c4d171098535102fb5fc14;ca3a26b2-ef3a-4bae-9db8-bbc324377d6e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-511' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-3f6046ce608acf1a45b020c8;93419641-2956-433d-b53a-30b0a23a32e9)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-512' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-72b29bd52aab2eca703d3869;94f90f19-ed87-455d-9a6c-bff724597807)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-513' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-5eca61091a7ba55219a49576;0fa81497-0406-45cb-a293-1f7db369f7b8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-514' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-0f03d6ca70353f16059a80b7;83548874-ac55-4db7-bf21-7a585d9e8838)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-515' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-54294af65a4e17af4f6dc8af;e83dc311-3d9c-44bd-ae52-3cb9246c47ae)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-516' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-5c0c53330d1545d060d3d0d2;8c7ca3e1-faa9-4862-8358-c7c62932c0b7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-517' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-77c682725a6a869726bcfe7f;08af7b89-b4b6-4b04-95a3-fb28a77d28d3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-518' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-2666b23a3720843624c20b24;bcc92c4b-7e34-4c61-803b-868c712e38be)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-519' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-3b3a454e16792b1a1a8104b4;5085403c-5bc6-4c1f-9278-9084eadb971b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-520' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-55b5cc8a63914a9303d19f25;6a2f5ff9-2e04-4f33-a3fc-f9d11048551b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-521' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-2e28e3e840f2c6390ad5cacc;feb67876-f813-4ba8-9d55-a5fd3b09c042)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-522' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-1222b3d651c71dce31eb4658;387131f4-eca4-46ad-825e-4ba35447701f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-523' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-610e14ac6080fcdf5bdb4629;d221792f-429b-4a6d-93e8-229994ce7e36)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-524' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-2d80be1b5e764ba052c72340;b5ca05e2-80a8-4811-afb6-29db1a3b4318)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-525' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-265f2975218b4c38698719b1;ecabe9b9-379d-4fcd-8e6b-b652901ca05f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-526' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-73d82a020baa017b78c3bd71;1a9cac8a-468d-4225-af54-ad7b8b88e8b2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-527' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-0134ae4213d3366d2e5a948d;9980d283-b170-4937-b516-d6eeb7a0da55)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-528' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-3ef70e8b79056354518e3f41;0b5db53e-2c51-4902-a93b-372c1837bbbd)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-529' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-3f7a85843738f77f3dc4ead7;d6b8a357-a4b6-4a24-b5ef-2b0ee0011f90)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-530' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7c-496a6837705ed8ac1faf34af;49cea571-2497-488b-b7ed-97ccb997b0d5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-531' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-3740c6686e6ffd1d229ed447;84c56b86-79c2-49f0-98c8-454d58213b5e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-532' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-1164962c78c6aebf5de4025f;eebe3f38-d6f2-476e-9c3b-97e06b2efd92)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-533' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-76f4359a7db9bb364f68d0b3;8ebef969-015e-4566-b0f2-38927da68a75)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-534' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-5fb313f22392b81423768ff4;5f6362af-fde9-4132-8388-8dac8499e951)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-535' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-5b08b8a75a10b47024a61dde;325b5610-781d-40b7-ae1c-04ed1813c504)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-536' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-6708141740624e715b1e4e6c;97ffaa08-3945-4ac6-a6ef-909e1b72e420)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-537' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-2ac4ea16098199c434846571;b378bc27-ea24-43cc-a967-2990f5da5ebc)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-538' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-19516bfb291b579a4d3b105e;1e9b4432-136f-4474-9681-0c228bc5e986)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-539' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-14d20fc069b657a3735a1287;08d64832-e7b3-4ca6-9334-aff4c68dee55)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-540' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-1eb53a5f1c66946c5726c254;3dbaa3fb-8519-463d-abba-7e87901e4dc7)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-541' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-21b86c4e4706c9b379d3267f;a16f19ed-1358-4669-a114-1ea8a81f2e2a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-542' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-3f7d93ad6f0cb6de36dbd7a5;ef6006eb-0d10-4f33-aaa2-b55de76ef090)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-543' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-4de97d764c309c6412368194;d38310b8-afb7-4b97-8e00-8314e57e9651)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-544' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-1bb87fc2285d4edb0cfb3649;f8fd45c2-4029-4c4b-9a5c-6080f2b7afa3)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-545' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-718bd9ac5bac3e7a43dafb23;a0e46b6d-c06e-4fb2-941e-41e0a4ef3873)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-546' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-4c764baa539010d6505b6476;f487ab89-4f6c-40d8-b5fe-a78e35ce2698)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-547' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-7f997c283bfb7a9f6b00e136;74b2eb79-ef83-4a39-8f0b-ba5646240541)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-548' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-63e151ad457ef0ca01a91ebd;aac318af-9d9b-420d-866f-7178dd5a87ed)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-549' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-034ade917cc14daf06d9e2d2;cbb49c93-05cc-4e41-a216-3a593d63228e)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-550' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-1ffff26f0fc61fae0104a165;1a9dea72-8471-4c3c-bc2f-9c76567dce06)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-551' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-3029f8c0522ba41f506b1fac;6dd368b8-334a-463d-9c5a-c58c68ef8f00)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-552' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7d-4571bac87f38cf45737c3601;99d6d5de-cd4f-43e0-9806-8cbf2d097299)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-553' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-69cf6ad6453c6006088a2195;7d42817a-ad6f-4204-8373-104d5e4040ee)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-554' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-61b70c156d20cb0a46657c88;89fdef83-12cc-4ba8-9158-1052f82205e8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-555' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-6e63efd02162222a2bef0cf9;e7f94967-cbfc-4cb2-9cd3-d71f8bb0404b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-556' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-2fca5ef804264ecb66f1b02b;95f8f2aa-f098-4356-90c7-dcb05080c9d8)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-557' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-347ce48b1588ed1a6872154a;1191d987-14de-4d2d-9209-4cb2714ce4bd)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-558' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-5a2dec650c952f2850b0ee08;93094253-9350-445c-b245-ef88e3d881b2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-559' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-7be734ee15f7d76e350203ea;48842453-68b8-4416-9fee-1f85a7ada6b4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-560' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-5b2f34d04e9f08d771f6b34e;f4066537-086f-487b-83b5-a842b325d650)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-561' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-3c52ad775d9a1f9278838210;99f0dd9d-cce7-4bdc-b802-3578d649a1fa)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-562' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-5102559b211178c17b094f88;fc614768-ae04-4d62-b41e-b8b0eae8563a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-563' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-2582c4ee0999c6cc69cf800c;ad30516d-9ea5-4aee-a518-7b4327b223b2)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-564' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-1e7700bb1520d8ea3c906153;e04ea535-78d0-48ac-a275-4a3b31b4544f)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-565' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-72de4969361b122172189dbf;b2dcc48e-79f1-4e43-be5a-b24fbc1da46a)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-566' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-67b513f15c29e34d60ac0d40;f8423d6d-ceb6-4d11-9f6e-cbe051ce0ff0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-567' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-279c574f7c3426ce5512b212;e7bf7c07-6077-408e-8714-99db1ed8325c)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-568' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-1066d72734c692136409d5f8;931e3c2c-8f00-4cb5-b1ad-ed7352df1d35)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-569' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-104f6e3d6fc1090b03fac91f;de3dbf07-fcec-4384-8c82-48081c6a0bea)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-570' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-51243f4c4cc32fa2584b5fa9;a60261a5-2f29-413a-b0b2-12f125637059)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-571' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-2e661c087e80d4b1483074c6;70b5797f-d1a3-4179-89c1-846c93566523)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-572' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-3192ba0d520c35731f91d3c1;811e04a9-3094-4691-aec4-4d6e6499b2b0)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-573' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-04935deb2bdd365f49204647;6e79d50b-b64e-4e1c-8dcb-bd11447158bc)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-574' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7e-1c0a060b45fa6ff76c8e3571;60e6110b-330f-42ec-ac08-9a7ca62ebc2d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-575' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-0c5740003ea34eb44353edf1;d21d85ac-f20e-417e-a7bd-32c55c560fd4)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-576' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-78144d674b6479af3deb4e0a;2ae98d9f-bdde-43e2-9c64-2da0831ef130)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-577' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-27981c8d3134a92633e4e93b;212f8e3b-4e7a-44cf-8f0c-fcea0bc2361d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-578' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-11664f3207c4bf7a012a717c;80e946a9-c8bd-43d1-bff2-49c68d0ecd98)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-579' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-69fcc309138a58ae0aa1443b;01d09598-cac2-4328-9c6c-d35befca2e73)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-580' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-52326b395e1a74da11081200;1978de60-3bfb-4b46-9684-6c7d10c97902)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-581' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-1b148abe459a5cb66cd0bc71;ad518b14-1a1b-4382-9e59-bb284cdc52e5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-582' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-1dc82a2842676a5d7cccdfdd;652d1ea8-9f4b-4585-8e2b-31b595169ff5)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-583' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-17687b7621379b6e33b3279a;bfc52006-12ab-4ce5-a844-820ce35e99da)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-584' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-0ecd76202e1cc3df7b1851ac;3215fd79-bfee-41ed-a4be-e76bf2d596af)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-585' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-7c4288c81b8d81856e74f737;ecff5959-43b6-4ba3-b834-83fcaaa84815)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-586' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-3d3d71d341edcdbb385ebdac;c61dee73-bf59-4fc5-8656-461e6aaa1543)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-587' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-12154df640cf24c3008ae3ed;d496702c-c134-45c1-8a23-a4fd14fc2cd1)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-588' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-41ed567153ae31e67aa9edc8;82b89bb8-7b37-4785-855b-11684b216911)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-589' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-6f8036943651fda9106095f1;f8a02375-7e5c-40d2-b72d-18eb24bb4762)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-590' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b7f-65d83cb223d3c77f759de3a9;605698b0-db6f-4b27-b5c0-1d661844e153)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-591' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-6b6608474685a06351b07038;f02b7075-09aa-462b-90c1-374e712cf773)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-592' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-10e437e5320aa8a2509477b5;964877a4-1d72-4d24-b307-6e38230edd0d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-593' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-37e3495b65d6fa385def5650;ede4e8cf-596c-4904-b6df-3073f3eb4a52)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-594' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-54cea215602eaa203197da86;b6a7b90c-0240-4184-bc97-4a071934004d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-595' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-5e2111a92a5b2d3573f8277c;afe15199-e1dd-4402-adee-9fd665c1ba07)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-596' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-45aaf96028061681092ed78f;595e0bf5-8fed-4f2c-a53d-118da302f91d)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-597' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-01e6e6e22d5e7841283f2c61;6622d457-51e1-41a7-92aa-4b59e97e01af)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-598' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-6cef0cff226610d02e1974ed;b11405c1-fe6e-4ad7-88ec-3f821635ac43)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-599' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-3d1b349425cbde372feaf195;9c0c43ee-4189-45e4-ad00-5f8251728d81)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-600' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-372b642008bc4324309a9cc4;841ac28d-ccf4-47df-999a-c03f93fb9f7b)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
[2025-12-23 03:06:10] ERROR base_events.py:1871: Task exception was never retrieved
future: <Task finished name='Task-601' coro=<main_async.<locals>.collect_single_question_translation_async() done, defined at /projects/bfdz/zluo8/tool_and_judge2/tool.py:112> exception=OSError("Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`")>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 402, in hf_raise_for_status
    response.raise_for_status()
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
    ...<12 lines>...
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<16 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1114, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1655, in _raise_on_head_call_error
    raise head_call_error
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
        url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
    ...<7 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
    ...<4 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py", line 307, in _request_wrapper
    hf_raise_for_status(response)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 452, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-694a5b80-74301e700fb85bd147846268;fc166f47-afa1-4c60-b449-9ae7c3313bdf)

Repository Not Found for url: https://huggingface.co/Qwen/Qwen3-32B-A3B/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 24, in create_vllm_backend
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 1089, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py", line 921, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
    ...<14 lines>...
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/utils/hub.py", line 511, in cached_files
    raise OSError(
    ...<4 lines>...
    ) from e
OSError: Qwen/Qwen3-32B-A3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
