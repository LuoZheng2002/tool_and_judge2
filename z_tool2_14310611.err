üîó Found pyo3 bindings
üêç Found CPython 3.13 at /projects/bfdz/zluo8/tool_and_judge2/.venv/bin/python
    Finished `release` profile [optimized] target(s) in 2.13s
üìñ Found type stub file at codebase_rs.pyi
üì¶ Built wheel for CPython 3.13 to /tmp/.tmpzoquQ1/codebase_rs-0.1.0-cp313-cp313-linux_x86_64.whl
üõ† Installed codebase_rs-0.1.0
/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py:1041: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(EngineCore_DP0 pid=539571)[0;0m Process EngineCore_DP0:
[0;36m(EngineCore_DP0 pid=539571)[0;0m Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/multiprocessing/process.py", line 313, in _bootstrap
[0;36m(EngineCore_DP0 pid=539571)[0;0m     self.run()
[0;36m(EngineCore_DP0 pid=539571)[0;0m     ~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/multiprocessing/process.py", line 108, in run
[0;36m(EngineCore_DP0 pid=539571)[0;0m     self._target(*self._args, **self._kwargs)
[0;36m(EngineCore_DP0 pid=539571)[0;0m     ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 847, in run_engine_core
[0;36m(EngineCore_DP0 pid=539571)[0;0m     raise e
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=539571)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m     super().__init__(
[0;36m(EngineCore_DP0 pid=539571)[0;0m     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=539571)[0;0m         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=539571)[0;0m         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m     )
[0;36m(EngineCore_DP0 pid=539571)[0;0m     ^
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=539571)[0;0m                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m     super().__init__(vllm_config)
[0;36m(EngineCore_DP0 pid=539571)[0;0m     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=539571)[0;0m     self._init_executor()
[0;36m(EngineCore_DP0 pid=539571)[0;0m     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py", line 174, in _init_executor
[0;36m(EngineCore_DP0 pid=539571)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
[0;36m(EngineCore_DP0 pid=539571)[0;0m                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=539571)[0;0m   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py", line 660, in wait_for_ready
[0;36m(EngineCore_DP0 pid=539571)[0;0m     raise e from None
[0;36m(EngineCore_DP0 pid=539571)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/multiprocessing/resource_tracker.py:301: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown: {'/psm_19a09d51'}
  warnings.warn(
/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py:1041: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/30 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:   3% Completed | 1/30 [00:01<00:54,  1.89s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:   7% Completed | 2/30 [00:04<01:01,  2.20s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  10% Completed | 3/30 [00:06<01:04,  2.39s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  13% Completed | 4/30 [00:08<00:58,  2.24s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  17% Completed | 5/30 [00:11<00:55,  2.23s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  20% Completed | 6/30 [00:13<00:56,  2.36s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  23% Completed | 7/30 [00:16<00:54,  2.38s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  27% Completed | 8/30 [00:18<00:52,  2.39s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  30% Completed | 9/30 [00:21<00:50,  2.42s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  33% Completed | 10/30 [00:23<00:46,  2.33s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  37% Completed | 11/30 [00:26<00:47,  2.50s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  40% Completed | 12/30 [00:28<00:45,  2.53s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  43% Completed | 13/30 [00:29<00:35,  2.08s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  47% Completed | 14/30 [00:32<00:34,  2.15s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  50% Completed | 15/30 [00:34<00:33,  2.21s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  53% Completed | 16/30 [00:36<00:29,  2.11s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  57% Completed | 17/30 [00:38<00:29,  2.29s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  60% Completed | 18/30 [00:41<00:28,  2.34s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  63% Completed | 19/30 [00:43<00:25,  2.36s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  67% Completed | 20/30 [00:46<00:25,  2.58s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  70% Completed | 21/30 [00:49<00:22,  2.49s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  73% Completed | 22/30 [00:52<00:21,  2.64s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  77% Completed | 23/30 [00:54<00:17,  2.48s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  80% Completed | 24/30 [00:56<00:14,  2.45s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  83% Completed | 25/30 [00:59<00:12,  2.57s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  87% Completed | 26/30 [01:02<00:10,  2.68s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  90% Completed | 27/30 [01:05<00:08,  2.69s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  93% Completed | 28/30 [01:07<00:05,  2.65s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards:  97% Completed | 29/30 [01:10<00:02,  2.60s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards: 100% Completed | 30/30 [01:12<00:00,  2.61s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Loading safetensors checkpoint shards: 100% Completed | 30/30 [01:12<00:00,  2.43s/it]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m 
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP1 pid=540155)[0;0m 2025-12-23 03:08:59,381 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP4 pid=540161)[0;0m 2025-12-23 03:08:59,381 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP2 pid=540157)[0;0m 2025-12-23 03:08:59,381 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m 2025-12-23 03:08:59,381 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP3 pid=540159)[0;0m 2025-12-23 03:08:59,381 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP7 pid=540167)[0;0m 2025-12-23 03:08:59,381 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP6 pid=540165)[0;0m 2025-12-23 03:08:59,381 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP5 pid=540163)[0;0m 2025-12-23 03:08:59,381 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP6 pid=540165)[0;0m 2025-12-23 03:08:59,444 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP4 pid=540161)[0;0m 2025-12-23 03:08:59,444 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP5 pid=540163)[0;0m 2025-12-23 03:08:59,453 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m 2025-12-23 03:08:59,514 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP1 pid=540155)[0;0m 2025-12-23 03:08:59,515 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP2 pid=540157)[0;0m 2025-12-23 03:08:59,517 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP7 pid=540167)[0;0m 2025-12-23 03:08:59,517 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP3 pid=540159)[0;0m 2025-12-23 03:08:59,526 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|‚ñé         | 1/35 [00:00<00:22,  1.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|‚ñå         | 2/35 [00:00<00:14,  2.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|‚ñä         | 3/35 [00:01<00:11,  2.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|‚ñà‚ñè        | 4/35 [00:01<00:10,  3.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|‚ñà‚ñç        | 5/35 [00:01<00:10,  2.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|‚ñà‚ñã        | 6/35 [00:02<00:09,  2.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|‚ñà‚ñà        | 7/35 [00:02<00:09,  3.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|‚ñà‚ñà‚ñé       | 8/35 [00:02<00:08,  3.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|‚ñà‚ñà‚ñå       | 9/35 [00:03<00:07,  3.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|‚ñà‚ñà‚ñä       | 10/35 [00:03<00:07,  3.45it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:03<00:06,  3.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:03<00:06,  3.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:04<00:06,  3.53it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:04<00:05,  3.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:04<00:05,  3.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:04<00:05,  3.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:05<00:04,  3.65it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:05<00:04,  3.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:05<00:04,  3.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [00:06<00:04,  3.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:06<00:04,  2.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:06<00:04,  3.00it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:07<00:04,  2.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:07<00:04,  2.50it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:08<00:03,  2.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:08<00:03,  2.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:08<00:02,  3.00it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:09<00:02,  3.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:09<00:01,  3.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:09<00:01,  3.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:09<00:01,  3.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:10<00:00,  3.65it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:10<00:00,  3.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:10<00:00,  4.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:10<00:00,  4.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:10<00:00,  3.23it/s]
[0;36m(EngineCore_DP0 pid=540147)[0;0m [0;36m(Worker_TP0 pid=540153)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   5%|‚ñå         | 1/19 [00:00<00:17,  1.02it/s]Capturing CUDA graphs (decode, FULL):  11%|‚ñà         | 2/19 [00:01<00:09,  1.76it/s]Capturing CUDA graphs (decode, FULL):  16%|‚ñà‚ñå        | 3/19 [00:01<00:06,  2.44it/s]Capturing CUDA graphs (decode, FULL):  21%|‚ñà‚ñà        | 4/19 [00:01<00:04,  3.28it/s]Capturing CUDA graphs (decode, FULL):  26%|‚ñà‚ñà‚ñã       | 5/19 [00:01<00:03,  3.61it/s]Capturing CUDA graphs (decode, FULL):  32%|‚ñà‚ñà‚ñà‚ñè      | 6/19 [00:02<00:03,  4.03it/s]Capturing CUDA graphs (decode, FULL):  37%|‚ñà‚ñà‚ñà‚ñã      | 7/19 [00:02<00:02,  4.64it/s]Capturing CUDA graphs (decode, FULL):  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 8/19 [00:02<00:02,  4.18it/s]Capturing CUDA graphs (decode, FULL):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 9/19 [00:02<00:02,  4.80it/s]Capturing CUDA graphs (decode, FULL):  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 10/19 [00:02<00:02,  3.99it/s]Capturing CUDA graphs (decode, FULL):  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 11/19 [00:03<00:02,  3.40it/s]Capturing CUDA graphs (decode, FULL):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 12/19 [00:03<00:01,  3.58it/s]Capturing CUDA graphs (decode, FULL):  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 13/19 [00:03<00:01,  3.56it/s]Capturing CUDA graphs (decode, FULL):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 14/19 [00:04<00:01,  3.72it/s]Capturing CUDA graphs (decode, FULL):  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 15/19 [00:04<00:01,  3.57it/s]Capturing CUDA graphs (decode, FULL):  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 16/19 [00:04<00:00,  4.15it/s]Capturing CUDA graphs (decode, FULL):  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 17/19 [00:04<00:00,  4.64it/s]Capturing CUDA graphs (decode, FULL):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 18/19 [00:04<00:00,  5.15it/s]Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:04<00:00,  3.84it/s]
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 456, in <module>
    asyncio.run(main_async())
    ~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/asyncio/base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 178, in main_async
    await collect_all_question_translations_async(question_entries)
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 173, in collect_all_question_translations_async
    result = await coro
             ^^^^^^^^^^
  File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/asyncio/tasks.py", line 634, in _wait_for_one
    return f.result() if resolve else f
           ~~~~~~~~^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 116, in collect_single_question_translation_async
    main_client, main_engine, main_tokenizer, main_is_api = create_backend(config.model)
                                                            ~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/tool.py", line 75, in create_backend
    engine, tokenizer = create_vllm_backend(local_model, num_gpus=args.num_gpus)
                        ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/src_py/vllm_backend.py", line 37, in create_vllm_backend
    engine = AsyncLLMEngine.from_engine_args(engine_args)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/async_llm.py", line 252, in from_engine_args
    return cls(
        vllm_config=vllm_config,
    ...<5 lines>...
        stat_loggers=stat_loggers,
    )
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/async_llm.py", line 134, in __init__
    self.engine_core = EngineCoreClient.make_async_mp_client(
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        vllm_config=vllm_config,
        ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        client_index=client_index,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core_client.py", line 121, in make_async_mp_client
    return AsyncMPClient(*client_args)
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core_client.py", line 810, in __init__
    super().__init__(
    ~~~~~~~~~~~~~~~~^
        asyncio_mode=True,
        ^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        client_addresses=client_addresses,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core_client.py", line 471, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/rh9.4/spack/v1.0.0/sw/linux-x86_64_v2/python-3.13.5-7bp2p4z/lib/python3.13/contextlib.py", line 148, in __exit__
    next(self.gen)
    ~~~~^^^^^^^^^^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        handshake_socket,
        ^^^^^^^^^^^^^^^^^
    ...<5 lines>...
        coordinator.proc if coordinator else None,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
    ...<3 lines>...
    )
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
[rank1]:[W1223 03:09:22.001982635 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=160, addr=[localhost]:49278, remote=[localhost]:35013): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:697 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f547e51cb80 in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x7f54c0925531 in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffe92d (0x7f54c092692d in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff4da (0x7f54c09274da in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7f54c09221fe in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x7f547f49f6b8 in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbad4 (0x7f54dd76bad4 in /lib64/libstdc++.so.6)
frame #7: <unknown function> + 0x89c0a (0x7f54f151bc0a in /lib64/libc.so.6)
frame #8: <unknown function> + 0x10ec60 (0x7f54f15a0c60 in /lib64/libc.so.6)

[rank2]:[W1223 03:09:22.001967512 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=164, addr=[localhost]:49320, remote=[localhost]:35013): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:697 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f547e51cb80 in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x7f54c0925531 in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffe92d (0x7f54c092692d in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff4da (0x7f54c09274da in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7f54c09221fe in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x7f547f49f6b8 in /projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbad4 (0x7f54dd76bad4 in /lib64/libstdc++.so.6)
frame #7: <unknown function> + 0x89c0a (0x7f54f151bc0a in /lib64/libc.so.6)
frame #8: <unknown function> + 0x10ec60 (0x7f54f15a0c60 in /lib64/libc.so.6)

[rank2]:[W1223 03:09:23.508385214 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0 Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[rank1]:[W1223 03:09:23.508390417 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0 Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
